{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher's Assignment No. 14 - Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Author:*** *Ofir Paz* $\\qquad$ ***Version:*** *12.05.2024* $\\qquad$ ***Course:*** *22961 - Deep Learning*\n",
    "\n",
    "Welcome to question 1 of the fourth assignment of the course *Deep Learning*. \\\n",
    "In this question, we will implement the *SplitLinear* network layer, and make various gradient calculations related to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will import the required packages for this assignment.\n",
    "- [pytorch](https://pytorch.org/) - One of the most fundemental and famous tensor handling library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # pytorch.\n",
    "import torch.nn as nn  # neural network module.\n",
    "import torch.nn.functional as F  # functional module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SplitLinear Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with the implementation of the *SplitLinear* layer, using pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitLinear(nn.Module):\n",
    "    '''SplitLinear layer.\n",
    "    \n",
    "    The SplitLinear layer is a linear layer that splits the input tensor in half, \n",
    "    applies a linear transformation to each half, and concatenates the results.\n",
    "    '''\n",
    "    def __init__(self, layer_size: int) -> None:\n",
    "        '''\n",
    "        Constructor for the SplitLinear layer.\n",
    "\n",
    "        Args:\n",
    "            layer_size (int) - Number of features. assumes even.\n",
    "        '''\n",
    "        super(SplitLinear, self).__init__()\n",
    "        self.linear = nn.Linear(layer_size // 2, layer_size // 2)\n",
    "\n",
    "        # Use Xavier initialization for the weights.\n",
    "        # Reasoning for use in the video.\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        nn.init.zeros_(self.linear.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        Forward pass of the layer.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor) - Input tensor.\n",
    "                Assumes shape (batch_size, #features), where #features is even.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor - Output tensor.\n",
    "        '''\n",
    "\n",
    "        # Split the input tensor in half.\n",
    "        x1, x2 = torch.chunk(x, 2, dim=1)\n",
    "\n",
    "        # Apply linear transformation to each half.\n",
    "        x1, x2 = self.linear(x1), self.linear(x2)\n",
    "\n",
    "        # Concatenate the results and apply ReLU.\n",
    "        x = F.relu(torch.cat([x1, x2], dim=1))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "X = tensor([[-0.3942,  0.4170, -1.4738, -0.9345, -0.6397, -1.0555],\n",
      "        [ 0.7832,  1.7541,  1.3419,  2.2032, -0.8232,  1.1084]])\n",
      "X.shape = torch.Size([2, 6])\n",
      "\n",
      "Split:\n",
      "X1 = tensor([[-0.3942,  0.4170, -1.4738],\n",
      "        [ 0.7832,  1.7541,  1.3419]])\n",
      "X2 = tensor([[-0.9345, -0.6397, -1.0555],\n",
      "        [ 2.2032, -0.8232,  1.1084]])\n",
      "X1.shape = torch.Size([2, 3])\n",
      "X2.shape = torch.Size([2, 3])\n",
      "\n",
      "Linear:\n",
      "Z1 = tensor([[ 0.6701,  1.4141,  0.8321],\n",
      "        [-1.1550, -3.5769,  0.1444]])\n",
      "Z2 = tensor([[ 0.2946,  2.4598, -0.2546],\n",
      "        [ 1.4591, -2.4159,  1.1164]])\n",
      "Z1.shape = torch.Size([2, 3])\n",
      "Z2.shape = torch.Size([2, 3])\n",
      "\n",
      "Output:\n",
      "Y = tensor([[0.0000, 0.4170, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7832, 1.7541, 1.3419, 2.2032, 0.0000, 1.1084]])\n",
      "Y.shape = torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "# Example if Single pass through the `SplitLinear` layer.\n",
    "split_linear = SplitLinear(6)\n",
    "\n",
    "# Random input tensor.\n",
    "X = torch.randn(2, 6)\n",
    "print(f\"Input:\\n{X = }\")\n",
    "print(f\"{X.shape = }\\n\")\n",
    "\n",
    "# Forward pass (not using `.forward` for printing each stage).\n",
    "with torch.no_grad():\n",
    "    X1, X2 = torch.chunk(X, 2, dim=1)\n",
    "    print(f\"Split:\\n{X1 = }\\n{X2 = }\")\n",
    "    print(f\"{X1.shape = }\\n{X2.shape = }\\n\")\n",
    "\n",
    "    Z1, Z2 = split_linear.linear(X1), split_linear.linear(X2)\n",
    "    print(f\"Linear:\\n{Z1 = }\\n{Z2 = }\")\n",
    "    print(f\"{Z1.shape = }\\n{Z2.shape = }\\n\")\n",
    "\n",
    "    Y = F.relu(torch.cat([X1, X2], dim=1))\n",
    "    print(f\"Output:\\n{Y = }\")\n",
    "    print(f\"{Y.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block diagram\n",
    "\n",
    "To easily understand the Split Linear layer, we can see the next block diagram that describes it.\n",
    "\n",
    "<img src=\"block_diagram_q1.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\def\\M2{\\frac{m}{2}}$\n",
    "## Analysis of SplitLinear vs. Standard Linear Layer\n",
    "### Parameters in SplitLinear Layer\n",
    "- Input size: $m$ (even)\n",
    "- Output size: $m$\n",
    "- Weight matrix: $(\\M2, \\M2)$\n",
    "- Bias vector: $(\\M2)$ (duplicated)\n",
    "- Total Parameters: $(\\M2)^2 + \\M2$\n",
    "\n",
    "### Parameters in Standard Linear Layer\n",
    "- Weight matrix: $(m, m)$\n",
    "- Bias vector: $(m)$\n",
    "- Total Parameters: $m^2 + m$\n",
    "\n",
    "### Ratio of Parameters\n",
    "$$\n",
    "\\frac{\\#SplitLinear}{\\#Linear}\n",
    "    = \\frac{(\\M2)^2 + \\M2}{m^2 + m} \n",
    "    = \\frac{\\frac{m}{4} + \\frac{1}{2}}{m + 1} \n",
    "    = \\frac{1}{4} \\cdot \\frac{m + \\frac{1}{8}}{m + 1}\n",
    "    \\xrightarrow[m \\rightarrow \\infty]{} \\frac{1}{4} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Calculating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\def\\d{\\delta} \\def\\M2{\\frac{M}{2}} \\providecommand{\\:}[2]{[#1 \\space : \\space #2]}$\n",
    "To caluculate the number of parameters in the `SplitLinear` layer, we can use the *chain rule*.\n",
    "\n",
    "We will start with $ \\frac{\\d C}{\\d W} $. Remember that $W$ and $b$ are of dimentions $ (\\M2, \\M2) $ and $ \\M2 $ \n",
    "respectively.\n",
    "\n",
    "Assuming we have $\\frac{\\d C}{\\d Y}$ already calculated, we get\n",
    "\n",
    "$$\n",
    "\\frac{\\d C}{\\d w_{p, q}} = \\frac{\\d C}{\\d Y_p} \\cdot \\frac{\\d Y_p}{\\d Z_p} \\cdot \\frac{\\d Z_p}{\\d w_{p, q}} \n",
    "                         + \\frac{\\d C}{\\d Y_{p + \\M2}} \n",
    "                           \\cdot \\frac{\\d Y_{p + \\M2}}{\\d Z_{p + \\M2}} \n",
    "                           \\cdot \\frac{\\d Z_{p + \\M2}}{\\d w_{p, q}}\n",
    "$$\n",
    "\n",
    "We can represent $Z$ as such\n",
    "\n",
    "$$\n",
    "Z = \\begin{bmatrix} W & 0 \\\\ 0 & W \\\\ \\end{bmatrix} \\begin{bmatrix} X_1 \\\\ X_2 \\end{bmatrix}\n",
    "  + \\begin{bmatrix} b \\\\ b \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Where $\\begin{bmatrix} {X_1}_{(\\M2)} & {X_2}_{(\\M2)} \\end{bmatrix} = X_{(M)}^T $. With this we can calculate\n",
    "\n",
    "$$\n",
    "\\frac{\\d Z_p}{\\d w_{p, q}} = {X_1}_q = X_q \\qquad \\text{and} \\qquad \n",
    "\\frac{\\d Z_{p + \\M2}}{\\d w_{p, q}} = {X_2}_q = X_{q + \\M2}\n",
    "$$\n",
    "\n",
    "The relation between $Y$ and $Z$ is that $ Y = \\text{ReLU}(Z) $, so\n",
    "\n",
    "$$\n",
    "\\frac{\\d Y_m}{\\d Z_m} = \n",
    "    \\begin{cases}\n",
    "        1, & \\text{if } Z_m \\geq 0 \\\\\n",
    "        0, & \\text{if } Z_m < 0\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "At the end we get\n",
    "\n",
    "$$\n",
    "\\boxed\n",
    "{\n",
    "\\frac{\\d C}{\\d w_{p, q}} = \\frac{\\d C}{\\d Y_p} \\cdot 1\\{Z_p \\geq 0\\} \\cdot X_q\n",
    "                         + \\frac{\\d C}{\\d Y_{p + \\M2}} \\cdot 1\\{Z_{p + \\M2} \\geq 0\\} \\cdot X_{q + \\M2}\n",
    "}\n",
    "$$\n",
    "\n",
    "We can also represent this in matrix form as such\n",
    "\n",
    "$$\n",
    "\\frac{\\d C}{\\d W} = \\frac{\\d C}{\\d Y}_{\\:{0}{\\M2}} \\otimes 1\\{Z_{\\:{0}{\\M2}} \\geq 0\\} \\cdot X_{\\:{0}{\\M2}}^T\n",
    "                  + \\frac{\\d C}{\\d Y}_{\\:{\\M2}{M}} \\otimes 1\\{Z_{\\:{\\M2}{M}} \\geq 0\\} \\cdot X_{\\:{\\M2}{M}}^T\n",
    "$$\n",
    "\n",
    "Where $\\otimes$ represents element to row product.\n",
    "\n",
    "Continuing with $ \\frac{\\d C}{\\d b} $, we can use the chain rule again to obtain\n",
    "\n",
    "$$\n",
    "\\frac{\\d C}{\\d b_m} = \\frac{\\d C}{\\d Y_m} \\cdot \\frac{\\d Y_m}{\\d Z_m} \\cdot \\frac{\\d Z_m}{\\d b_m} \n",
    "                     +  \\frac{\\d C}{\\d Y_{m + \\M2}} \n",
    "                        \\cdot \\frac{\\d Y_{m + \\M2}}{\\d Z_{m + \\M2}} \n",
    "                        \\cdot \\frac{\\d Z_{m + \\M2}}{\\d b_m}\n",
    "$$\n",
    "\n",
    "and by the representation of $Z$ we get\n",
    "\n",
    "$$\n",
    "\\frac{\\d Z_m}{\\d b_m} = 1 \\qquad \\text{and} \\qquad \\frac{\\d Z_{m + \\M2}}{\\d b_m} = 1\n",
    "$$\n",
    "\n",
    "$ \\frac{\\d Y_m}{\\d Z_m} $ was already calculated so we finally get\n",
    "\n",
    "$$\n",
    "\\boxed\n",
    "{\n",
    "\\frac{\\d C}{\\d b_m} = \\frac{\\d C}{\\d Y_m} \\cdot 1\\{Z_m \\geq 0\\}\n",
    "                    + \\frac{\\d C}{\\d Y_{m + \\M2}} \\cdot 1\\{Z_{m + \\M2} \\geq 0\\}\n",
    "}\n",
    "$$\n",
    "\n",
    "We can represent this too in matrix form as such\n",
    "\n",
    "$$\n",
    "\\frac{\\d C}{\\d b} = \\frac{\\d C}{\\d Y}_{\\:{0}{\\M2}} \\otimes 1\\{Z_{\\:{0}{\\M2}} \\geq 0\\}\n",
    "                  + \\frac{\\d C}{\\d Y}_{\\:{\\M2}{M}} \\otimes 1\\{Z_{\\:{\\M2}{M}} \\geq 0\\}\n",
    "$$\n",
    "\n",
    "Where now $\\otimes$ represents element wise product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\def\\M4{\\frac{M}{4}}$\n",
    "If we were to change this network layer such that the input would split into four equal parts, the gradients will be sum of 4 elements:\n",
    "\n",
    "$$\n",
    "\\frac{\\d C}{\\d w_{p, q}} = \\sum_{i = 0}^3\n",
    "    \\frac{\\d C}{\\d Y_{p + i \\cdot \\M4}} \\cdot 1\\{Z_{p + i \\cdot \\M4} \\geq 0\\} \\cdot X_{q + i \\cdot \\M4}\n",
    "\\newline\n",
    "\n",
    "\\frac{\\d C}{\\d b_m} = \\sum_{i = 0}^3 \\frac{\\d C}{\\d Y_{m + i \\cdot \\M4}} \\cdot 1\\{Z_{m + i \\cdot M4} \\geq 0\\}\n",
    "$$\n",
    "\n",
    "Where now $W$ and $b$ are of dimentions $ (\\M4, \\M4) $ and $ \\M4 $ respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
