{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher's Assignment No. 15 - Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Author:*** *Ofir Paz* $\\qquad$ ***Version:*** *15.05.2024* $\\qquad$ ***Course:*** *22961 - Deep Learning*\n",
    "\n",
    "Welcome to the first question of the fifth assignment of the course *Deep Learning*. \\\n",
    "In this question we will implement the functionality of `nn.Conv2d`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will import the required packages for this assignment\n",
    "- [pytorch](https://pytorch.org/) - One of the most fundemental and famous tensor handling library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch  # pytorch.\n",
    "import torch.nn as nn  # neural network module.\n",
    "import torch.optim as optim  # optimization module.\n",
    "import torch.nn.functional as F  # functional module.\n",
    "import numpy as np  # numpy.\n",
    "import torch.utils.data  # data handling module.\n",
    "import matplotlib.pyplot as plt  # plotting module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2d Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(nn.Module):\n",
    "    '''Conv2d implementation.\n",
    "\n",
    "    Implements a 2D convolutional layer, without using any of the \n",
    "    functions from the module `torch.nn`.\n",
    "    '''\n",
    "    def __init__(self, in_channels: int = 1, out_channels: int = 1, \n",
    "                 kernel_size: Tuple[int, int] = (1, 1), stride: int = 1, padding: int = 0) -> None:\n",
    "        '''Conv2d constructore\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): number of input channels.\n",
    "            out_channels (int): number of output channels.\n",
    "            kernel_size (Tuple[int, int]): kernel size.\n",
    "            stride (int): stride.\n",
    "            padding (int): padding.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        '''\n",
    "        super(Conv2d, self).__init__()\n",
    "\n",
    "        # initialize kernels and bias.\n",
    "        self.kernels: torch.Tensor = nn.Parameter(torch.rand(out_channels, in_channels, *kernel_size))\n",
    "        self.bias: torch.Tensor = nn.Parameter(torch.zeros(out_channels))\n",
    "\n",
    "        # save parameters.\n",
    "        self.p, self.q = kernel_size\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): input tensor. Assumes shape (N, C, H, W).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: output tensor, with shape (N, out_channels, H', W').\n",
    "        '''\n",
    "        assert x.dim() == 4, \\\n",
    "            f'Input tensor must have 4 dimensions. Got {x.dim()} dimensions.'\n",
    "        assert x.size(1) == self.in_channels, \\\n",
    "            f'Input tensor must have the same number of channels as the layer. Got {x.size(1)} channels.'\n",
    "        assert x.size(2) >= self.p, \\\n",
    "            f'Input tensor must have a height greater than the kernel size. Got {x.size(2)} height.'\n",
    "        assert x.size(3) >= self.q, \\\n",
    "            f'Input tensor must have a width greater than the kernel size. Got {x.size(3)} width.'\n",
    "\n",
    "        out_shape = lambda n, f: (n + 2 * self.padding - f) // self.stride + 1\n",
    "        output = torch.zeros(x.size(0), self.out_channels, \n",
    "                             out_shape(x.size(2), self.p), out_shape(x.size(3), self.q))\n",
    "        \n",
    "        if self.padding > 0:\n",
    "            x_padded = torch.zeros(x.size(0), x.size(1), \n",
    "                                   x.size(2) + 2 * self.padding, x.size(3) + 2 * self.padding)\n",
    "            x_padded[:, :, self.padding : -self.padding, self.padding : -self.padding] = x\n",
    "            x = x_padded\n",
    "        \n",
    "        for c in range(output.size(1)):\n",
    "            for h in range(output.size(2)):\n",
    "                for w in range(output.size(3)):\n",
    "                    sh, sw = h * self.stride, w * self.stride\n",
    "                    sub_img = x[:, :, sh : sh + self.p, sw : sw + self.q]\n",
    "                    output[:, c, h, w] = (sub_img * self.kernels[c]).sum(dim=(1,2,3)) + self.bias[c]\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validating the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Conv2d forward method *passed* with input shape torch.Size([1, 6, 32, 32]) and parameters \n",
      "    {'in_channels': 6, 'out_channels': 10, 'kernel_size': (3, 3), 'stride': 1, 'padding': 1}.\n",
      "[2] Conv2d forward method *passed* with input shape torch.Size([16, 8, 42, 40]) and parameters \n",
      "    {'in_channels': 8, 'out_channels': 2, 'kernel_size': (5, 4), 'stride': 2, 'padding': 1}.\n",
      "[3] Conv2d forward method *passed* with input shape torch.Size([10, 2, 53, 34]) and parameters \n",
      "    {'in_channels': 2, 'out_channels': 2, 'kernel_size': (1, 1), 'stride': 1, 'padding': 2}.\n",
      "[4] Conv2d forward method *passed* with input shape torch.Size([1, 10, 20, 20]) and parameters \n",
      "    {'in_channels': 10, 'out_channels': 10, 'kernel_size': (6, 8), 'stride': 3, 'padding': 3}.\n",
      "[5] Conv2d forward method *passed* with input shape torch.Size([2, 4, 10, 10]) and parameters \n",
      "    {'in_channels': 4, 'out_channels': 5, 'kernel_size': (5, 5), 'stride': 2, 'padding': 4}.\n"
     ]
    }
   ],
   "source": [
    "# Unit tests for the Conv2d class.\n",
    "class Conv2dTestCase():\n",
    "    def __init__(self):\n",
    "        # Set random seed for reproducibility.\n",
    "        torch.manual_seed(0)\n",
    "        np.random.seed(0)\n",
    "    \n",
    "        # List of dicts containing parameters for input tensors.\n",
    "        self.tensor_inputs = [\n",
    "            {'size': (1, 6, 32, 32)},\n",
    "            {'size': (16, 8, 42, 40)},\n",
    "            {'size': (10, 2, 53, 34)},\n",
    "            {'size': (1, 10, 20, 20)},\n",
    "            {'size': (2, 4, 10, 10)}\n",
    "        ]\n",
    "\n",
    "        # List of dictionaries containing the parameters for the Conv2d layer.\n",
    "        self.conv_inputs = [\n",
    "            {'in_channels': 6, 'out_channels': 10, 'kernel_size': (3, 3), 'stride': 1, 'padding': 1},\n",
    "            {'in_channels': 8, 'out_channels': 2, 'kernel_size': (5, 4), 'stride': 2, 'padding': 1},\n",
    "            {'in_channels': 2, 'out_channels': 2, 'kernel_size': (1, 1), 'stride': 1, 'padding': 2},\n",
    "            {'in_channels': 10, 'out_channels': 10, 'kernel_size': (6, 8), 'stride': 3, 'padding': 3},\n",
    "            {'in_channels': 4, 'out_channels': 5, 'kernel_size': (5, 5), 'stride': 2, 'padding': 4}\n",
    "        ]\n",
    "\n",
    "    def test_forward(self) -> None:\n",
    "        '''Test the forward method of the Conv2d class.'''\n",
    "\n",
    "        for i, (conv_input, tensor_input) in enumerate(zip(self.conv_inputs, self.tensor_inputs)):\n",
    "            # Create Conv2d instance.\n",
    "            conv2d = Conv2d(**conv_input)\n",
    "\n",
    "            # Create nn.Conv2d instance.\n",
    "            nn_conv2d = nn.Conv2d(**conv_input)\n",
    "\n",
    "            # Set both parameters to be the same.\n",
    "            nn_conv2d.weight.data = conv2d.kernels\n",
    "            nn_conv2d.bias.data = conv2d.bias  # type: ignore\n",
    "\n",
    "            # Create input tensor.\n",
    "            input_tensor = torch.rand(**tensor_input)\n",
    "\n",
    "            # Forward pass through Conv2d.\n",
    "            output = conv2d(input_tensor)\n",
    "\n",
    "            # Forward pass through nn.Conv2d.\n",
    "            nn_output = nn_conv2d(input_tensor)\n",
    "\n",
    "            # Compare the outputs.\n",
    "            assert torch.allclose(output, nn_output) == True, \\\n",
    "                f\"\"\"Conv2d forward method *failed* with input shape {input_tensor.size()} \n",
    "                and parameters \\n    {conv_input}.\"\"\"\n",
    "            \n",
    "            print(f'[{i+1}] Conv2d forward method *passed* with input shape {input_tensor.size()} '\n",
    "                  f'and parameters \\n    {conv_input}.')\n",
    "\n",
    "tester = Conv2dTestCase()\n",
    "tester.test_forward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
