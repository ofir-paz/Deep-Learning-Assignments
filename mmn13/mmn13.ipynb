{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher's Assignment No. 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Author:*** *Ofir Paz* $\\qquad$ ***Version:*** *20.04.2024* $\\qquad$ ***Course:*** *22961 - Deep Learning*\n",
    "\n",
    "Welcome to the third assignment of the course *Deep Learning*. \\\n",
    "In this assignment we will explore Pytorch's DataLoader, and use it to train a neural network for classification purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will import the required packages for this assignment.\n",
    "- [pytorch](https://pytorch.org/) - One of the most fundemental and famous tensor handling library.\n",
    "- [numpy](https://numpy.org) - The fundamental package for scientific computing with Python.\n",
    "- [pandas](https://pandas.pydata.org) - Library to handle data in Python.\n",
    "- [matplotlib](https://matplotlib.org) - Library to plot graphs in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # pytorch.\n",
    "import torch.nn as nn  # neural network module.\n",
    "import torch.optim as optim  # optimization module.\n",
    "import torch.nn.functional as F  # functional module.\n",
    "import numpy as np  # numpy.\n",
    "import torchvision.transforms as transforms  # image transformation module.\n",
    "from torch.utils.data import DataLoader, Dataset  # data loader and dataset base class.\n",
    "from torchmetrics import Accuracy  # accuracy metric.\n",
    "import pandas as pd  # handling data.\n",
    "import matplotlib.pyplot as plt  # plotting.\n",
    "from typing import Literal  # type hinting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will handle the pre processing of the provided *Diabetes dataset*. The Diabetes dataset is a csv file containing 442 different records for different patients holding information about the patient, and an additional column (Y) with the Diabetes' progression rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>157</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>183</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>156</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>198</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>192</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SEX   BMI     BP   S1     S2    S3   S4      S5  S6    Y\n",
       "0   59    2  32.1  101.0  157   93.2  38.0  4.0  4.8598  87  151\n",
       "1   48    1  21.6   87.0  183  103.2  70.0  3.0  3.8918  69   75\n",
       "2   72    2  30.5   93.0  156   93.6  41.0  4.0  4.6728  85  141\n",
       "3   24    1  25.3   84.0  198  131.4  40.0  5.0  4.8903  89  206\n",
       "4   50    1  23.0  101.0  192  125.4  52.0  4.0  4.2905  80  135"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset with pandas.\n",
    "data = pd.read_csv('diabetes.csv', sep='\\t')\n",
    "\n",
    "# Display the first 5 rows of the dataset.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to divide the dataset to $10$ classes which represent the tenth precentile of the value of $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>Y</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>157</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87</td>\n",
       "      <td>151</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>183</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>156</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85</td>\n",
       "      <td>141</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>198</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89</td>\n",
       "      <td>206</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>192</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80</td>\n",
       "      <td>135</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SEX   BMI     BP   S1     S2    S3   S4      S5  S6    Y  Class\n",
       "0   59    2  32.1  101.0  157   93.2  38.0  4.0  4.8598  87  151    5.0\n",
       "1   48    1  21.6   87.0  183  103.2  70.0  3.0  3.8918  69   75    1.0\n",
       "2   72    2  30.5   93.0  156   93.6  41.0  4.0  4.6728  85  141    5.0\n",
       "3   24    1  25.3   84.0  198  131.4  40.0  5.0  4.8903  89  206    7.0\n",
       "4   50    1  23.0  101.0  192  125.4  52.0  4.0  4.2905  80  135    4.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_labeled_data(data: pd.DataFrame, num_precentiles: int = 10) -> pd.DataFrame:\n",
    "    # Copy the original dataset.\n",
    "    labeled_data = data.copy()\n",
    "\n",
    "    # Create the new column `Class` and initialize it with NaN.\n",
    "    labeled_data['Class'] = np.NaN\n",
    "\n",
    "    # Iterate over the percentiles.\n",
    "    for klass in np.arange(num_precentiles):\n",
    "        # Calculate the k-th percentile of the column 'Y'.\n",
    "        percentile = data['Y'].quantile(klass / num_precentiles)\n",
    "\n",
    "        # Label the matching class for all rows where \n",
    "        #  the value of 'Y' is greater or equal to the percentile.\n",
    "        labeled_data.loc[(data['Y'] >= percentile).values, 'Class'] = klass\n",
    "\n",
    "    return labeled_data\n",
    "\n",
    "tenth_percentile_data = get_labeled_data(data, num_precentiles=10)\n",
    "\n",
    "tenth_percentile_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create the wraper pytorch dataset to hold the labeled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, transform: transforms.Compose | None = None, \n",
    "                 drop_Y: bool = False):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.drop_Y = drop_Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        x = row.drop('Class')\n",
    "        if self.drop_Y:\n",
    "            x = x.drop('Y')\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        y = row['Class']\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use pytorch's dataloader to create a data loader for the dataset and display a single mini-batch of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "TRAIN_VAL_RATIO = 0.8\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: torch.from_numpy(x.values.astype(np.float32))),\n",
    "    # transforms.Lambda(lambda x: (x - x.mean()) / x.std()),\n",
    "])\n",
    "\n",
    "# Split the dataset into a training and a validation set.\n",
    "train_data = tenth_percentile_data.sample(frac=TRAIN_VAL_RATIO, random_state=42)\n",
    "val_data = tenth_percentile_data.drop(train_data.index)\n",
    "\n",
    "# Create the datasets.\n",
    "train_dataset_with_Y = DiabetesDataset(train_data, transform=transform)\n",
    "val_dataset_with_Y = DiabetesDataset(val_data, transform=transform)\n",
    "\n",
    "# Create the dataloaders.\n",
    "train_loader_with_Y = DataLoader(train_dataset_with_Y, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_with_Y = DataLoader(val_dataset_with_Y, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 11]) tensor([[ 55.0000,   1.0000,  23.0000,  94.6700, 190.0000, 137.6000,  38.0000,\n",
      "           5.0000,   4.2767, 106.0000, 146.0000],\n",
      "        [ 53.0000,   1.0000,  28.6000,  88.0000, 171.0000,  98.8000,  41.0000,\n",
      "           4.0000,   5.0499,  99.0000, 265.0000],\n",
      "        [ 26.0000,   2.0000,  30.3000,  89.0000, 218.0000, 152.2000,  31.0000,\n",
      "           7.0000,   5.1591,  82.0000, 137.0000],\n",
      "        [ 46.0000,   2.0000,  23.8000,  97.0000, 224.0000, 139.2000,  42.0000,\n",
      "           5.0000,   5.3660,  81.0000, 209.0000],\n",
      "        [ 52.0000,   1.0000,  24.5000,  90.0000, 198.0000, 129.0000,  29.0000,\n",
      "           7.0000,   5.2983,  86.0000, 233.0000],\n",
      "        [ 54.0000,   2.0000,  27.3000, 100.0000, 200.0000, 144.0000,  33.0000,\n",
      "           6.0000,   4.7449,  76.0000, 235.0000],\n",
      "        [ 71.0000,   2.0000,  27.0000,  93.3300, 269.0000, 190.2000,  41.0000,\n",
      "           6.5600,   5.2417,  93.0000, 131.0000],\n",
      "        [ 49.0000,   1.0000,  25.6000,  76.0000, 161.0000,  99.8000,  51.0000,\n",
      "           3.0000,   3.9318,  78.0000,  31.0000],\n",
      "        [ 53.0000,   1.0000,  24.1000, 105.0000, 184.0000, 113.4000,  46.0000,\n",
      "           4.0000,   4.8122,  95.0000,  66.0000],\n",
      "        [ 60.0000,   2.0000,  28.2000, 112.0000, 185.0000, 113.8000,  42.0000,\n",
      "           4.0000,   4.9836,  93.0000, 178.0000]])\n",
      "torch.Size([10]) tensor([5, 9, 4, 7, 8, 8, 4, 0, 1, 6])\n"
     ]
    }
   ],
   "source": [
    "# Print a mini-batch.\n",
    "for x, y in train_loader_with_Y:\n",
    "    print(x.shape, x)  # 10 samples with 11 features each.\n",
    "    print(y.shape, y)  # 10 labels.\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will design the architecture for the *Neural Network* (NN) to classify the tenth precentile of the Diabetes' progression, and train it. We will use the data loader defined above and `torch.nn` to create the architecture. Since we have a small dataset with only $11$ features, we will simply create a fully connected NN with a small number of layers and neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesPrecentileClassifer(nn.Module):\n",
    "    def __init__(self, input_size: int = 11, num_classes: int = 10):\n",
    "        super(DiabetesPrecentileClassifer, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 15)\n",
    "        self.fc2 = nn.Linear(15, 30)\n",
    "        self.fc3 = nn.Linear(30, 30)\n",
    "        self.fc4 = nn.Linear(30, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block introduces the train loop function. The train loop iterates over the dataloader and uses the optimizer and criterion to update the NN weights in the gradient decent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, data_loader: DataLoader, num_epochs: int = 30, lr: float = 0.001, \n",
    "          wd: float = 0., loss_func: Literal['log', 'MSE'] = 'log', try_cuda: bool = False,\n",
    "          print_cost: bool = False, print_stride: int = 1) -> list[float]:\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    \n",
    "    :param model: The model to train.\n",
    "    :param data_loader: The data loader.\n",
    "    :param num_epochs: The number of epochs.\n",
    "    :param lr: The learning rate.\n",
    "    :param wd: The weight decay.\n",
    "    :param loss_func: The loss function to use can either be `log` or `MSE`.\n",
    "    :param try_cuda: A flag indicating if the model should be trained on the GPU.\n",
    "    :param print_cost: A flag indicating if the cost should be printed.\n",
    "    :param print_stride: The stride for printing the cost.\n",
    "    :return: The total cost of each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs: list[float] = []\n",
    "    \n",
    "    use_cuda = try_cuda and torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        print(\"Using CUDA for traininig.\")\n",
    "        model = model.cuda()\n",
    "\n",
    "    # Create the optimizer and criterion.\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    criterion = nn.CrossEntropyLoss() if loss_func == 'log' else nn.MSELoss()  # log or MSE.\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.\n",
    "        for x, y in data_loader:\n",
    "            if use_cuda:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            y_hat = model(x)\n",
    "\n",
    "            if loss_func == 'MSE':\n",
    "                y = y.float()\n",
    "                y_hat = y_hat.squeeze()\n",
    "            \n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calc loss\n",
    "            lloss = loss.item()\n",
    "            running_loss += lloss * x.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / (len(data_loader) * BATCH_SIZE)\n",
    "        costs.append(epoch_loss)\n",
    "            \n",
    "        if print_cost and (epoch % print_stride == 0 or epoch == num_epochs - 1):\n",
    "            print(f\"\\r[epoch: {epoch+1}/{num_epochs}] Total Loss: {epoch_loss}\")\n",
    "\n",
    "    return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1/150] Total Loss: 2.873996202150981\n",
      "[epoch: 21/150] Total Loss: 0.7551723611023691\n",
      "[epoch: 41/150] Total Loss: 0.6652364141411251\n",
      "[epoch: 61/150] Total Loss: 0.6551922620998488\n",
      "[epoch: 81/150] Total Loss: 0.5652710263927777\n",
      "[epoch: 101/150] Total Loss: 0.5620862090753185\n",
      "[epoch: 121/150] Total Loss: 0.5066907885173957\n",
      "[epoch: 141/150] Total Loss: 0.4674604301651319\n",
      "[epoch: 150/150] Total Loss: 0.5143173951241705\n",
      "\n",
      "REDUCED LEARNING RATE TO 0.0001\n",
      "\n",
      "[epoch: 1/75] Total Loss: 0.4257424954738882\n",
      "[epoch: 21/75] Total Loss: 0.38944191936817435\n",
      "[epoch: 41/75] Total Loss: 0.38571395302812256\n",
      "[epoch: 61/75] Total Loss: 0.38490768290228317\n",
      "[epoch: 75/75] Total Loss: 0.3756044932537609\n"
     ]
    }
   ],
   "source": [
    "# Train the network.\n",
    "classifer_with_Y = DiabetesPrecentileClassifer()\n",
    "\n",
    "train(classifer_with_Y, train_loader_with_Y, num_epochs=150, lr=0.001,\n",
    "      print_cost=True, print_stride=20)\n",
    "print(\"\\nREDUCED LEARNING RATE TO 0.0001\\n\")\n",
    "train(classifer_with_Y, train_loader_with_Y, num_epochs=75, lr=0.0001,\n",
    "      print_cost=True, print_stride=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, data_loader: DataLoader) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the model.\n",
    "    \n",
    "    :param model: The model.\n",
    "    :param data_loader: The data loader.\n",
    "    :return: The accuracy\n",
    "    \"\"\"\n",
    "    accuracy_module = Accuracy(task=\"multiclass\", num_classes=model.fc4.out_features)\n",
    "    all_prob_preditions, all_labels = torch.tensor([]), torch.tensor([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            prob_preditions = model(inputs)\n",
    "            all_prob_preditions = torch.cat((all_prob_preditions, prob_preditions))\n",
    "            all_labels = torch.cat((all_labels, labels))\n",
    "\n",
    "    accuracy = accuracy_module(all_prob_preditions.argmax(dim=-1), all_labels)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.49%\n",
      "Accuracy: 67.05%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the network.\n",
    "print(f\"Accuracy: {evaluate(classifer_with_Y, train_loader_with_Y):.2%}\")\n",
    "print(f\"Accuracy: {evaluate(classifer_with_Y, val_loader_with_Y):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1/150] Total Loss: 2.4558302376005385\n",
      "[epoch: 21/150] Total Loss: 1.9178077313635085\n",
      "[epoch: 41/150] Total Loss: 1.8125113877985213\n",
      "[epoch: 61/150] Total Loss: 1.7671432495117188\n",
      "[epoch: 81/150] Total Loss: 1.660578227043152\n",
      "[epoch: 101/150] Total Loss: 1.5875573853651683\n",
      "[epoch: 121/150] Total Loss: 1.5395028074582418\n",
      "[epoch: 141/150] Total Loss: 1.4479724413818784\n",
      "[epoch: 150/150] Total Loss: 1.458085294895702\n",
      "\n",
      "REDUCED LEARNING RATE TO 0.0001\n",
      "\n",
      "[epoch: 1/75] Total Loss: 1.3553193463219537\n",
      "[epoch: 21/75] Total Loss: 1.3223698907428318\n",
      "[epoch: 41/75] Total Loss: 1.306242338485188\n",
      "[epoch: 61/75] Total Loss: 1.2972087423006693\n",
      "[epoch: 75/75] Total Loss: 1.2914809743563334\n"
     ]
    }
   ],
   "source": [
    "# Create the datasets without the `Y` values.\n",
    "train_dataset_without_Y = DiabetesDataset(train_data, transform=transform, drop_Y=True)\n",
    "val_dataset_without_Y = DiabetesDataset(val_data, transform=transform, drop_Y=True)\n",
    "\n",
    "# Create the dataloaders without the `Y` values.\n",
    "train_loader_without_Y = DataLoader(train_dataset_without_Y, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_without_Y = DataLoader(val_dataset_without_Y, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Create the model without the `Y` values.\n",
    "classifer_without_Y = DiabetesPrecentileClassifer(input_size=10)\n",
    "\n",
    "train(classifer_without_Y, train_loader_without_Y, num_epochs=150, lr=0.001,\n",
    "      print_cost=True, print_stride=20)\n",
    "print(\"\\nREDUCED LEARNING RATE TO 0.0001\\n\")\n",
    "train(classifer_without_Y, train_loader_without_Y, num_epochs=75, lr=0.0001,\n",
    "      print_cost=True, print_stride=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.26%\n",
      "Accuracy: 19.32%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {evaluate(classifer_without_Y, train_loader_without_Y):.2%}\")\n",
    "print(f\"Accuracy: {evaluate(classifer_without_Y, val_loader_without_Y):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained two neural networks on the dataset to predict the classes. One of the neural networks had the `Y` values as a feature, and the other one didn't. The classes were directly computed through the `Y` values, thus it is expected that the first NN will perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will divide the dataset to $100$ classes instead of $10$ and train the networks again on this new dataset. The classes will now represent the hundredth precentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change dataset to hundredth percentile instead of tenth precentile.\n",
    "hundredth_percentile_data = get_labeled_data(data, num_precentiles=100)\n",
    "\n",
    "# Split the dataset into a training and a validation set.\n",
    "train_hundredth_precentile = hundredth_percentile_data.sample(frac=TRAIN_VAL_RATIO, random_state=42)\n",
    "val_hundredth_precentile = hundredth_percentile_data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1/150] Total Loss: 5.2099314570426944\n",
      "[epoch: 21/150] Total Loss: 0.8114013034436438\n",
      "[epoch: 41/150] Total Loss: 0.7122957885265351\n",
      "[epoch: 61/150] Total Loss: 0.6551700068844689\n",
      "[epoch: 81/150] Total Loss: 0.6347943844066726\n",
      "[epoch: 101/150] Total Loss: 0.6074779878060023\n",
      "[epoch: 121/150] Total Loss: 0.5805866906212436\n",
      "[epoch: 141/150] Total Loss: 0.5189092259440157\n",
      "[epoch: 150/150] Total Loss: 0.5086257276435693\n",
      "\n",
      "REDUCED LEARNING RATE TO 0.0001\n",
      "\n",
      "[epoch: 1/75] Total Loss: 0.45550413736038736\n",
      "[epoch: 21/75] Total Loss: 0.4403919524616665\n",
      "[epoch: 41/75] Total Loss: 0.4334119126200676\n",
      "[epoch: 61/75] Total Loss: 0.4286404980553521\n",
      "[epoch: 75/75] Total Loss: 0.4212534281114737\n",
      "Accuracy: 1.13%\n",
      "Accuracy: 1.14%\n"
     ]
    }
   ],
   "source": [
    "# Train network with `Y` values.\n",
    "\n",
    "# Create the datasets.\n",
    "train_dataset100_with_Y = DiabetesDataset(train_hundredth_precentile, transform=transform)\n",
    "val_dataset100_with_Y = DiabetesDataset(val_hundredth_precentile, transform=transform)\n",
    "\n",
    "# Create the dataloaders.\n",
    "train_loader100_with_Y = DataLoader(train_dataset100_with_Y, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader100_with_Y = DataLoader(val_dataset100_with_Y, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Create the neural network.\n",
    "classifer100_with_Y = DiabetesPrecentileClassifer(input_size=11, num_classes=100)\n",
    "\n",
    "# Train the network.\n",
    "train(classifer100_with_Y, train_loader_with_Y, num_epochs=150, lr=0.001,\n",
    "      print_cost=True, print_stride=20)\n",
    "print(\"\\nREDUCED LEARNING RATE TO 0.0001\\n\")\n",
    "train(classifer100_with_Y, train_loader_with_Y, num_epochs=75, lr=0.0001,\n",
    "      print_cost=True, print_stride=20);\n",
    "\n",
    "# Evaluate the network.\n",
    "print(f\"Accuracy: {evaluate(classifer100_with_Y, train_loader100_with_Y):.2%}\")\n",
    "print(f\"Accuracy: {evaluate(classifer100_with_Y, val_loader100_with_Y):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1/150] Total Loss: 5.487525765101115\n",
      "[epoch: 21/150] Total Loss: 3.770982829729716\n",
      "[epoch: 41/150] Total Loss: 3.371075839466519\n",
      "[epoch: 61/150] Total Loss: 2.987810382578108\n",
      "[epoch: 81/150] Total Loss: 2.575882848766115\n",
      "[epoch: 101/150] Total Loss: 2.2734833406077493\n",
      "[epoch: 121/150] Total Loss: 1.9971642090214623\n",
      "[epoch: 141/150] Total Loss: 1.725299224588606\n",
      "[epoch: 150/150] Total Loss: 1.6525369736883375\n",
      "\n",
      "REDUCED LEARNING RATE TO 0.0001\n",
      "\n",
      "[epoch: 1/75] Total Loss: 1.4956371002727085\n",
      "[epoch: 21/75] Total Loss: 1.3792361434963014\n",
      "[epoch: 41/75] Total Loss: 1.3478642731904984\n",
      "[epoch: 61/75] Total Loss: 1.328977722591824\n",
      "[epoch: 75/75] Total Loss: 1.3037893353237047\n",
      "Accuracy: 64.69%\n",
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Train network without `Y` values.\n",
    "\n",
    "# Create the datasets.\n",
    "train_dataset100_without_Y = DiabetesDataset(train_hundredth_precentile, transform=transform, drop_Y=True)\n",
    "val_dataset100_without_Y = DiabetesDataset(val_hundredth_precentile, transform=transform, drop_Y=True)\n",
    "\n",
    "# Create the dataloaders.\n",
    "train_loader100_without_Y = DataLoader(train_dataset100_without_Y, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader100_without_Y = DataLoader(val_dataset100_without_Y, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Create the neural network.\n",
    "classifer100_without_Y = DiabetesPrecentileClassifer(input_size=10, num_classes=100)\n",
    "\n",
    "# Train the network.\n",
    "train(classifer100_without_Y, train_loader100_without_Y, num_epochs=150, lr=0.001,\n",
    "      print_cost=True, print_stride=20)\n",
    "print(\"\\nREDUCED LEARNING RATE TO 0.0001\\n\")\n",
    "train(classifer100_without_Y, train_loader100_without_Y, num_epochs=75, lr=0.0001,\n",
    "      print_cost=True, print_stride=20)\n",
    "\n",
    "# Evaluate the network.\n",
    "print(f\"Accuracy: {evaluate(classifer100_without_Y, train_loader100_without_Y):.2%}\")\n",
    "print(f\"Accuracy: {evaluate(classifer100_without_Y, val_loader100_without_Y):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We experience much worse results, that is because the dataset is too small (around $4$ instances of each class) to successfully learn how to predict a class out of $100$ classes. It is preferable to use the tenth precentile as classes instead of the hundredth precentile, since the added accuracy in the `Y` prediction gained from the $100$ classes prediction is a lesser of a gain than the added overall accuracy of the $10$ classes prediction network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 POINTS BONNUS\n",
    "# Train a regression network on the dataset.\n",
    "# First, redfine the dataset to be a regression dataset.\n",
    "class DiabetesRegressionDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, transform: transforms.Compose | None = None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        x = row.drop('Y')\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        y = row['Y']\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "# Create a specific network architecture for regression.\n",
    "class DiabetesRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiabetesRegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA for traininig.\n",
      "[epoch: 1/300] Total Loss: 23614.38343290441\n",
      "[epoch: 21/300] Total Loss: 3661.51876953125\n",
      "[epoch: 41/300] Total Loss: 2869.50208984375\n",
      "[epoch: 61/300] Total Loss: 2692.8055388327207\n",
      "[epoch: 81/300] Total Loss: 2605.936144875919\n",
      "[epoch: 101/300] Total Loss: 2497.112819967831\n",
      "[epoch: 121/300] Total Loss: 2578.360021829044\n",
      "[epoch: 141/300] Total Loss: 3108.028125\n",
      "[epoch: 161/300] Total Loss: 2490.8186994485295\n",
      "[epoch: 181/300] Total Loss: 2343.503718405331\n",
      "[epoch: 201/300] Total Loss: 2293.7829032628674\n",
      "[epoch: 221/300] Total Loss: 2359.3113861443017\n",
      "[epoch: 241/300] Total Loss: 2210.9206430951285\n",
      "[epoch: 261/300] Total Loss: 2169.8064970128676\n",
      "[epoch: 281/300] Total Loss: 2159.011867532169\n",
      "[epoch: 300/300] Total Loss: 2549.445388327206\n",
      "\n",
      "REDUCED LEARNING RATE TO 0.0001\n",
      "\n",
      "Using CUDA for traininig.\n",
      "[epoch: 1/150] Total Loss: 2236.5238453584557\n",
      "[epoch: 21/150] Total Loss: 2068.9676298253676\n",
      "[epoch: 41/150] Total Loss: 2057.761062155331\n",
      "[epoch: 61/150] Total Loss: 2052.995867991728\n",
      "[epoch: 81/150] Total Loss: 2038.5471714154412\n",
      "[epoch: 101/150] Total Loss: 2038.808182444853\n",
      "[epoch: 121/150] Total Loss: 2036.0442606847425\n",
      "[epoch: 141/150] Total Loss: 2029.7467891199449\n",
      "[epoch: 150/150] Total Loss: 2031.295518727022\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now, train the network the usual way.\n",
    "# We change the output layer to have a single neuron and no activation function.\n",
    "# We also change the loss function to be the mean squared error (MSE).\n",
    "BATCH_SIZE = 85\n",
    "\n",
    "# Split the dataset into a training and a validation set.\n",
    "train_reg_data = data.sample(frac=TRAIN_VAL_RATIO, random_state=42)\n",
    "val_reg_data = data.drop(train_data.index)\n",
    "\n",
    "# Create the datasets.\n",
    "train_dataset_regression = DiabetesRegressionDataset(train_reg_data, transform=transform)\n",
    "val_dataset_regression = DiabetesRegressionDataset(val_reg_data, transform=transform)\n",
    "\n",
    "# Create the dataloaders.\n",
    "train_loader_regression = DataLoader(train_dataset_regression, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_regression = DataLoader(val_dataset_regression, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Create the neural network.\n",
    "classifer_regression = DiabetesRegressionModel()\n",
    "\n",
    "# Train the network.\n",
    "costs1 = train(classifer_regression, train_loader_regression, num_epochs=300, lr=0.001, wd=0.001,\n",
    "               loss_func='MSE', try_cuda=True, print_cost=True, print_stride=20)\n",
    "print(\"\\nREDUCED LEARNING RATE TO 0.0001\\n\")\n",
    "costs2 = train(classifer_regression, train_loader_regression, num_epochs=150, lr=0.0001, wd=0.001,\n",
    "               loss_func='MSE', try_cuda=True, print_cost=True, print_stride=20)\n",
    "\n",
    "# Evaluate the network.\n",
    "regression_costs = np.array(costs1 + costs2)\n",
    "\n",
    "plt.plot(regression_costs)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 2442.41\n",
      "Validation MSE: 3263.32\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the network.\n",
    "X_train : np.ndarray = train_reg_data.drop('Y', axis=1).values\n",
    "y_train : np.ndarray = train_reg_data['Y'].values  # type: ignore\n",
    "X_val : np.ndarray = val_reg_data.drop('Y', axis=1).values\n",
    "y_val : np.ndarray = val_reg_data['Y'].values  # type: ignore\n",
    "\n",
    "with torch.no_grad():\n",
    "    classifer_regression.cpu().eval()\n",
    "    y_hat_train = classifer_regression(torch.from_numpy(X_train).float()).squeeze()\n",
    "    y_hat_val = classifer_regression(torch.from_numpy(X_val).float()).squeeze()\n",
    "\n",
    "train_mse = F.mse_loss(y_hat_train, torch.from_numpy(y_train)).item()\n",
    "val_mse = F.mse_loss(y_hat_val, torch.from_numpy(y_val)).item()\n",
    "\n",
    "print(f\"Train MSE: {train_mse:.2f}\")\n",
    "print(f\"Validation MSE: {val_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Mean Squared Error: 2921.68\n",
      "[VAL] Mean Squared Error: 3499.15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219</td>\n",
       "      <td>152.105512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>184.812960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202</td>\n",
       "      <td>146.868610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230</td>\n",
       "      <td>289.457952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111</td>\n",
       "      <td>121.516933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84</td>\n",
       "      <td>97.097443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>242</td>\n",
       "      <td>242.917343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>272</td>\n",
       "      <td>196.659051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94</td>\n",
       "      <td>92.474037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>96</td>\n",
       "      <td>115.884416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   True   Predicted\n",
       "0   219  152.105512\n",
       "1    70  184.812960\n",
       "2   202  146.868610\n",
       "3   230  289.457952\n",
       "4   111  121.516933\n",
       "5    84   97.097443\n",
       "6   242  242.917343\n",
       "7   272  196.659051\n",
       "8    94   92.474037\n",
       "9    96  115.884416"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparison with normal linear regression.\n",
    "X : np.ndarray = train_reg_data.drop('Y', axis=1).values\n",
    "y : np.ndarray = train_reg_data['Y'].values  # type: ignore\n",
    "\n",
    "w = np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "\n",
    "y_hat = X @ w\n",
    "\n",
    "train_mse = np.mean((y - y_hat) ** 2)\n",
    "val_mse = np.mean((y_val - X_val @ w) ** 2)  # type: ignore\n",
    "\n",
    "print(f\"[TRAIN] Mean Squared Error: {train_mse:.2f}\")\n",
    "print(f\"[VAL] Mean Squared Error: {val_mse:.2f}\")\n",
    "\n",
    "pd.DataFrame({'True': y, 'Predicted': y_hat}).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
