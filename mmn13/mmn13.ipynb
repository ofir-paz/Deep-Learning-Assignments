{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher's Assignment No. 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Author:*** *Ofir Paz* $\\qquad$ ***Version:*** *20.04.2024* $\\qquad$ ***Course:*** *22961 - Deep Learning*\n",
    "\n",
    "Welcome to the third assignment of the course *Deep Learning*. \\\n",
    "In this assignment we will explore Pytorch's DataLoader, and use it to train a neural network for classification purposes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will import the required packages for this assignment.\n",
    "- [pytorch](https://pytorch.org/) - One of the most fundemental and famous tensor handling library.\n",
    "- [numpy](https://numpy.org) - The fundamental package for scientific computing with Python.\n",
    "- [pandas](https://pandas.pydata.org) - Library to handle data in Python.\n",
    "- [matplotlib](https://matplotlib.org) - Library to plot graphs in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # pytorch.\n",
    "import torch.nn as nn  # neural network module.\n",
    "import torch.optim as optim  # optimization module.\n",
    "import torch.nn.functional as F  # functional module.\n",
    "import numpy as np  # numpy.\n",
    "import torchvision.transforms as transforms  # image transformation module.\n",
    "from torch.utils.data import DataLoader, Dataset  # data loader and dataset base class.\n",
    "from torchmetrics import Accuracy  # accuracy metric.\n",
    "import pandas as pd  # handling data.\n",
    "import matplotlib.pyplot as plt  # plotting.\n",
    "from typing import Literal  # type hinting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will handle the pre processing of the provided *Diabetes dataset*. The Diabetes dataset is a csv file containing 442 different records for different patients holding information about the patient, and an additional column (Y) with the Diabetes' progression rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "AGE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SEX",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "BMI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "S1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "S2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "S3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "S4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "S5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "S6",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Y",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "63d9c764-c8ef-4e19-ad94-49192e25fd3b",
       "rows": [
        [
         "0",
         "59",
         "2",
         "32.1",
         "101.0",
         "157",
         "93.2",
         "38.0",
         "4.0",
         "4.8598",
         "87",
         "151"
        ],
        [
         "1",
         "48",
         "1",
         "21.6",
         "87.0",
         "183",
         "103.2",
         "70.0",
         "3.0",
         "3.8918",
         "69",
         "75"
        ],
        [
         "2",
         "72",
         "2",
         "30.5",
         "93.0",
         "156",
         "93.6",
         "41.0",
         "4.0",
         "4.6728",
         "85",
         "141"
        ],
        [
         "3",
         "24",
         "1",
         "25.3",
         "84.0",
         "198",
         "131.4",
         "40.0",
         "5.0",
         "4.8903",
         "89",
         "206"
        ],
        [
         "4",
         "50",
         "1",
         "23.0",
         "101.0",
         "192",
         "125.4",
         "52.0",
         "4.0",
         "4.2905",
         "80",
         "135"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>157</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>183</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>156</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>198</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>192</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SEX   BMI     BP   S1     S2    S3   S4      S5  S6    Y\n",
       "0   59    2  32.1  101.0  157   93.2  38.0  4.0  4.8598  87  151\n",
       "1   48    1  21.6   87.0  183  103.2  70.0  3.0  3.8918  69   75\n",
       "2   72    2  30.5   93.0  156   93.6  41.0  4.0  4.6728  85  141\n",
       "3   24    1  25.3   84.0  198  131.4  40.0  5.0  4.8903  89  206\n",
       "4   50    1  23.0  101.0  192  125.4  52.0  4.0  4.2905  80  135"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset with pandas.\n",
    "data = pd.read_csv('diabetes.csv', sep='\\t')\n",
    "\n",
    "# Display the first 5 rows of the dataset.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to divide the dataset to $10$ classes which represent the tenth precentile of the value of $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "AGE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SEX",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "BMI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "S1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "S2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "S3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "S4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "S5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "S6",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Y",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Class",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "647c71f8-81c8-4c01-8504-059d7a5ce5d5",
       "rows": [
        [
         "0",
         "59",
         "2",
         "32.1",
         "101.0",
         "157",
         "93.2",
         "38.0",
         "4.0",
         "4.8598",
         "87",
         "151",
         "5.0"
        ],
        [
         "1",
         "48",
         "1",
         "21.6",
         "87.0",
         "183",
         "103.2",
         "70.0",
         "3.0",
         "3.8918",
         "69",
         "75",
         "1.0"
        ],
        [
         "2",
         "72",
         "2",
         "30.5",
         "93.0",
         "156",
         "93.6",
         "41.0",
         "4.0",
         "4.6728",
         "85",
         "141",
         "5.0"
        ],
        [
         "3",
         "24",
         "1",
         "25.3",
         "84.0",
         "198",
         "131.4",
         "40.0",
         "5.0",
         "4.8903",
         "89",
         "206",
         "7.0"
        ],
        [
         "4",
         "50",
         "1",
         "23.0",
         "101.0",
         "192",
         "125.4",
         "52.0",
         "4.0",
         "4.2905",
         "80",
         "135",
         "4.0"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>Y</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>157</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87</td>\n",
       "      <td>151</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>183</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>156</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85</td>\n",
       "      <td>141</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>198</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89</td>\n",
       "      <td>206</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>192</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80</td>\n",
       "      <td>135</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SEX   BMI     BP   S1     S2    S3   S4      S5  S6    Y  Class\n",
       "0   59    2  32.1  101.0  157   93.2  38.0  4.0  4.8598  87  151    5.0\n",
       "1   48    1  21.6   87.0  183  103.2  70.0  3.0  3.8918  69   75    1.0\n",
       "2   72    2  30.5   93.0  156   93.6  41.0  4.0  4.6728  85  141    5.0\n",
       "3   24    1  25.3   84.0  198  131.4  40.0  5.0  4.8903  89  206    7.0\n",
       "4   50    1  23.0  101.0  192  125.4  52.0  4.0  4.2905  80  135    4.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_labeled_data(data: pd.DataFrame, num_precentiles: int = 10) -> pd.DataFrame:\n",
    "    # Copy the original dataset.\n",
    "    labeled_data = data.copy()\n",
    "\n",
    "    # Create the new column `Class` and initialize it with NaN.\n",
    "    labeled_data['Class'] = np.NaN\n",
    "\n",
    "    # Iterate over the percentiles.\n",
    "    for klass in np.arange(num_precentiles):\n",
    "        # Calculate the k-th percentile of the column 'Y'.\n",
    "        percentile = data['Y'].quantile(klass / num_precentiles)\n",
    "\n",
    "        # Label the matching class for all rows where \n",
    "        #  the value of 'Y' is greater or equal to the percentile.\n",
    "        labeled_data.loc[(data['Y'] >= percentile).values, 'Class'] = klass\n",
    "\n",
    "    return labeled_data\n",
    "\n",
    "tenth_percentile_data = get_labeled_data(data, num_precentiles=10)\n",
    "\n",
    "tenth_percentile_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create the wraper pytorch dataset to hold the labeled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, transform: transforms.Compose | None = None, \n",
    "                 drop_Y: bool = False):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.drop_Y = drop_Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        x = row.drop('Class')\n",
    "        if self.drop_Y:\n",
    "            x = x.drop('Y')\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        y = row['Class']\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use pytorch's dataloader to create a data loader for the dataset and display a single mini-batch of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "TRAIN_VAL_RATIO = 0.8\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: torch.from_numpy(x.values.astype(np.float32))),\n",
    "    # transforms.Lambda(lambda x: (x - x.mean()) / x.std()),\n",
    "])\n",
    "\n",
    "# Split the dataset into a training and a validation set.\n",
    "train_data = tenth_percentile_data.sample(frac=TRAIN_VAL_RATIO, random_state=42)\n",
    "val_data = tenth_percentile_data.drop(train_data.index)\n",
    "\n",
    "# Create the datasets.\n",
    "train_dataset_with_Y = DiabetesDataset(train_data, transform=transform)\n",
    "val_dataset_with_Y = DiabetesDataset(val_data, transform=transform)\n",
    "\n",
    "# Create the dataloaders.\n",
    "train_loader_with_Y = DataLoader(train_dataset_with_Y, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_with_Y = DataLoader(val_dataset_with_Y, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 11]) tensor([[ 40.0000,   1.0000,  26.9000,  92.0000, 203.0000, 119.8000,  70.0000,\n",
      "           3.0000,   4.1897,  81.0000,  60.0000],\n",
      "        [ 39.0000,   2.0000,  24.0000,  89.6700, 190.0000, 113.6000,  52.0000,\n",
      "           3.6500,   4.8040, 101.0000,  74.0000],\n",
      "        [ 67.0000,   2.0000,  23.0000,  70.0000, 184.0000, 128.0000,  35.0000,\n",
      "           5.0000,   4.6540,  99.0000, 102.0000],\n",
      "        [ 52.0000,   1.0000,  28.5000, 110.0000, 195.0000,  97.2000,  60.0000,\n",
      "           3.0000,   5.2417,  85.0000, 265.0000],\n",
      "        [ 49.0000,   2.0000,  28.8000,  92.0000, 207.0000, 140.0000,  44.0000,\n",
      "           5.0000,   4.7449,  92.0000, 196.0000],\n",
      "        [ 42.0000,   2.0000,  30.6000, 101.0000, 269.0000, 172.2000,  50.0000,\n",
      "           5.0000,   5.4553, 106.0000, 272.0000],\n",
      "        [ 62.0000,   2.0000,  37.8000, 119.0000, 113.0000,  51.0000,  31.0000,\n",
      "           4.0000,   5.0434,  84.0000, 281.0000],\n",
      "        [ 51.0000,   2.0000,  28.1000, 106.0000, 202.0000, 122.2000,  55.0000,\n",
      "           4.0000,   4.8203,  87.0000, 265.0000],\n",
      "        [ 41.0000,   1.0000,  32.4000,  94.0000, 171.0000, 104.4000,  56.0000,\n",
      "           3.0000,   3.9703,  76.0000,  95.0000],\n",
      "        [ 60.0000,   2.0000,  33.0000,  97.0000, 217.0000, 125.6000,  45.0000,\n",
      "           5.0000,   5.4467, 112.0000, 295.0000]])\n",
      "torch.Size([10]) tensor([1, 1, 3, 9, 6, 9, 9, 9, 3, 9])\n"
     ]
    }
   ],
   "source": [
    "# Print a mini-batch.\n",
    "for x, y in train_loader_with_Y:\n",
    "    print(x.shape, x)  # 10 samples with 11 features each.\n",
    "    print(y.shape, y)  # 10 labels.\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will design the architecture for the *Neural Network* (NN) to classify the tenth precentile of the Diabetes' progression, and train it. We will use the data loader defined above and `torch.nn` to create the architecture. Since we have a small dataset with only $11$ features, we will simply create a fully connected NN with a small number of layers and neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesPrecentileClassifer(nn.Module):\n",
    "    def __init__(self, input_size: int = 11, num_classes: int = 10):\n",
    "        super(DiabetesPrecentileClassifer, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 15)\n",
    "        self.fc2 = nn.Linear(15, 30)\n",
    "        self.fc3 = nn.Linear(30, 30)\n",
    "        self.fc4 = nn.Linear(30, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block introduces the train loop function. The train loop iterates over the dataloader and uses the optimizer and criterion to update the NN weights in the gradient decent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, data_loader: DataLoader, num_epochs: int = 30, lr: float = 0.001, \n",
    "          wd: float = 0., loss_func: Literal['log', 'MSE'] = 'log', try_cuda: bool = False,\n",
    "          print_cost: bool = False, print_stride: int = 1) -> list[float]:\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    \n",
    "    :param model: The model to train.\n",
    "    :param data_loader: The data loader.\n",
    "    :param num_epochs: The number of epochs.\n",
    "    :param lr: The learning rate.\n",
    "    :param wd: The weight decay.\n",
    "    :param loss_func: The loss function to use can either be `log` or `MSE`.\n",
    "    :param try_cuda: A flag indicating if the model should be trained on the GPU.\n",
    "    :param print_cost: A flag indicating if the cost should be printed.\n",
    "    :param print_stride: The stride for printing the cost.\n",
    "    :return: The total cost of each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs: list[float] = []\n",
    "    \n",
    "    use_cuda = try_cuda and torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        print(\"Using CUDA for traininig.\")\n",
    "        model = model.cuda()\n",
    "\n",
    "    # Create the optimizer and criterion.\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    criterion = nn.CrossEntropyLoss() if loss_func == 'log' else nn.MSELoss()  # log or MSE.\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.\n",
    "        for x, y in data_loader:\n",
    "            if use_cuda:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            y_hat = model(x)\n",
    "\n",
    "            if loss_func == 'MSE':\n",
    "                y = y.float()\n",
    "                y_hat = y_hat.squeeze()\n",
    "            \n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calc loss\n",
    "            lloss = loss.item()\n",
    "            running_loss += lloss * x.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / (len(data_loader) * BATCH_SIZE)\n",
    "        costs.append(epoch_loss)\n",
    "            \n",
    "        if print_cost and (epoch % print_stride == 0 or epoch == num_epochs - 1):\n",
    "            print(f\"\\r[epoch: {epoch+1}/{num_epochs}] Total Loss: {epoch_loss}\")\n",
    "\n",
    "    return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1/150] Total Loss: 2.4342058327462937\n",
      "[epoch: 21/150] Total Loss: 0.7517108311255772\n",
      "[epoch: 41/150] Total Loss: 0.6538090634677145\n",
      "[epoch: 61/150] Total Loss: 0.6072984392444293\n",
      "[epoch: 81/150] Total Loss: 0.5127835932705137\n",
      "[epoch: 101/150] Total Loss: 0.443278653257423\n",
      "[epoch: 121/150] Total Loss: 0.4374127498103513\n",
      "[epoch: 141/150] Total Loss: 0.353976913748516\n",
      "[epoch: 150/150] Total Loss: 0.3325123645572199\n",
      "\n",
      "REDUCED LEARNING RATE TO 0.0001\n",
      "\n",
      "[epoch: 1/75] Total Loss: 0.29542886890057063\n",
      "[epoch: 21/75] Total Loss: 0.26321720619582467\n",
      "[epoch: 41/75] Total Loss: 0.2605279503597154\n",
      "[epoch: 61/75] Total Loss: 0.25168392195676764\n",
      "[epoch: 75/75] Total Loss: 0.24475348111655976\n"
     ]
    }
   ],
   "source": [
    "# Train the network.\n",
    "classifer_with_Y = DiabetesPrecentileClassifer()\n",
    "\n",
    "train(classifer_with_Y, train_loader_with_Y, num_epochs=150, lr=0.001,\n",
    "      print_cost=True, print_stride=20)\n",
    "print(\"\\nREDUCED LEARNING RATE TO 0.0001\\n\")\n",
    "train(classifer_with_Y, train_loader_with_Y, num_epochs=75, lr=0.0001,\n",
    "      print_cost=True, print_stride=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module, data_loader: DataLoader) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the model.\n",
    "    \n",
    "    :param model: The model.\n",
    "    :param data_loader: The data loader.\n",
    "    :return: The accuracy\n",
    "    \"\"\"\n",
    "    accuracy_module = Accuracy(task=\"multiclass\", num_classes=model.fc4.out_features)\n",
    "    all_prob_preditions, all_labels = torch.tensor([]), torch.tensor([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            prob_preditions = model(inputs)\n",
    "            all_prob_preditions = torch.cat((all_prob_preditions, prob_preditions))\n",
    "            all_labels = torch.cat((all_labels, labels))\n",
    "\n",
    "    accuracy = accuracy_module(all_prob_preditions.argmax(dim=-1), all_labels)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.53%\n",
      "Accuracy: 62.50%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the network.\n",
    "print(f\"Accuracy: {evaluate(classifer_with_Y, train_loader_with_Y):.2%}\")\n",
    "print(f\"Accuracy: {evaluate(classifer_with_Y, val_loader_with_Y):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1/150] Total Loss: 3.280482749144236\n",
      "[epoch: 21/150] Total Loss: 2.1021368351247576\n",
      "[epoch: 41/150] Total Loss: 2.071967985894945\n",
      "[epoch: 61/150] Total Loss: 1.984591962893804\n",
      "[epoch: 81/150] Total Loss: 1.8943229430251651\n",
      "[epoch: 101/150] Total Loss: 1.8363903277450138\n",
      "[epoch: 121/150] Total Loss: 1.7934266852007972\n",
      "[epoch: 141/150] Total Loss: 1.7298329638110266\n",
      "[epoch: 150/150] Total Loss: 1.714059164788988\n",
      "\n",
      "REDUCED LEARNING RATE TO 0.0001\n",
      "\n",
      "[epoch: 1/75] Total Loss: 1.6626202868090736\n",
      "[epoch: 21/75] Total Loss: 1.6351635621653662\n",
      "[epoch: 41/75] Total Loss: 1.6283966329362658\n",
      "[epoch: 61/75] Total Loss: 1.6174910253948636\n",
      "[epoch: 75/75] Total Loss: 1.616446562608083\n"
     ]
    }
   ],
   "source": [
    "# Create the datasets without the `Y` values.\n",
    "train_dataset_without_Y = DiabetesDataset(train_data, transform=transform, drop_Y=True)\n",
    "val_dataset_without_Y = DiabetesDataset(val_data, transform=transform, drop_Y=True)\n",
    "\n",
    "# Create the dataloaders without the `Y` values.\n",
    "train_loader_without_Y = DataLoader(train_dataset_without_Y, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_without_Y = DataLoader(val_dataset_without_Y, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Create the model without the `Y` values.\n",
    "classifer_without_Y = DiabetesPrecentileClassifer(input_size=10)\n",
    "\n",
    "train(classifer_without_Y, train_loader_without_Y, num_epochs=150, lr=0.001,\n",
    "      print_cost=True, print_stride=20)\n",
    "print(\"\\nREDUCED LEARNING RATE TO 0.0001\\n\")\n",
    "train(classifer_without_Y, train_loader_without_Y, num_epochs=75, lr=0.0001,\n",
    "      print_cost=True, print_stride=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.27%\n",
      "Accuracy: 20.45%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {evaluate(classifer_without_Y, train_loader_without_Y):.2%}\")\n",
    "print(f\"Accuracy: {evaluate(classifer_without_Y, val_loader_without_Y):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trained two neural networks on the dataset to predict the classes. One of the neural networks had the `Y` values as a feature, and the other one didn't. The classes were directly computed through the `Y` values, thus it is expected that the first NN will perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will divide the dataset to $100$ classes instead of $10$ and train the networks again on this new dataset. The classes will now represent the hundredth precentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change dataset to hundredth percentile instead of tenth precentile.\n",
    "hundredth_percentile_data = get_labeled_data(data, num_precentiles=100)\n",
    "\n",
    "# Split the dataset into a training and a validation set.\n",
    "train_hundredth_precentile = hundredth_percentile_data.sample(frac=TRAIN_VAL_RATIO, random_state=42)\n",
    "val_hundredth_precentile = hundredth_percentile_data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1/150] Total Loss: 4.256832452615102\n",
      "[epoch: 21/150] Total Loss: 0.9712860590881771\n",
      "[epoch: 41/150] Total Loss: 0.7745967502395312\n",
      "[epoch: 61/150] Total Loss: 0.6743948052326838\n",
      "[epoch: 81/150] Total Loss: 0.6577784018384085\n",
      "[epoch: 101/150] Total Loss: 0.5942750328116947\n",
      "[epoch: 121/150] Total Loss: 0.5255563501682546\n",
      "[epoch: 141/150] Total Loss: 0.4844900245467822\n",
      "[epoch: 150/150] Total Loss: 0.4774617311027315\n",
      "\n",
      "REDUCED LEARNING RATE TO 0.0001\n",
      "\n",
      "[epoch: 1/75] Total Loss: 0.4162844518820445\n",
      "[epoch: 21/75] Total Loss: 0.36305952444672585\n",
      "[epoch: 41/75] Total Loss: 0.35241012275218964\n",
      "[epoch: 61/75] Total Loss: 0.3462689245740573\n",
      "[epoch: 75/75] Total Loss: 0.3425384440355831\n",
      "Accuracy: 1.13%\n",
      "Accuracy: 1.14%\n"
     ]
    }
   ],
   "source": [
    "# Train network with `Y` values.\n",
    "\n",
    "# Create the datasets.\n",
    "train_dataset100_with_Y = DiabetesDataset(train_hundredth_precentile, transform=transform)\n",
    "val_dataset100_with_Y = DiabetesDataset(val_hundredth_precentile, transform=transform)\n",
    "\n",
    "# Create the dataloaders.\n",
    "train_loader100_with_Y = DataLoader(train_dataset100_with_Y, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader100_with_Y = DataLoader(val_dataset100_with_Y, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Create the neural network.\n",
    "classifer100_with_Y = DiabetesPrecentileClassifer(input_size=11, num_classes=100)\n",
    "\n",
    "# Train the network.\n",
    "train(classifer100_with_Y, train_loader_with_Y, num_epochs=150, lr=0.001,\n",
    "      print_cost=True, print_stride=20)\n",
    "print(\"\\nREDUCED LEARNING RATE TO 0.0001\\n\")\n",
    "train(classifer100_with_Y, train_loader_with_Y, num_epochs=75, lr=0.0001,\n",
    "      print_cost=True, print_stride=20);\n",
    "\n",
    "# Evaluate the network.\n",
    "print(f\"Accuracy: {evaluate(classifer100_with_Y, train_loader100_with_Y):.2%}\")\n",
    "print(f\"Accuracy: {evaluate(classifer100_with_Y, val_loader100_with_Y):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1/150] Total Loss: 5.294299369388156\n",
      "[epoch: 21/150] Total Loss: 3.971191370487213\n",
      "[epoch: 41/150] Total Loss: 3.3947664499282837\n",
      "[epoch: 61/150] Total Loss: 2.990166578027937\n",
      "[epoch: 81/150] Total Loss: 2.607801759905285\n",
      "[epoch: 101/150] Total Loss: 2.3179384979936812\n",
      "[epoch: 121/150] Total Loss: 2.083756031592687\n",
      "[epoch: 141/150] Total Loss: 1.8778610024187299\n",
      "[epoch: 150/150] Total Loss: 1.7741478039158716\n",
      "\n",
      "REDUCED LEARNING RATE TO 0.0001\n",
      "\n",
      "[epoch: 1/75] Total Loss: 1.6678357481956483\n",
      "[epoch: 21/75] Total Loss: 1.530374107758204\n",
      "[epoch: 41/75] Total Loss: 1.5014174080557294\n",
      "[epoch: 61/75] Total Loss: 1.4773450715674294\n",
      "[epoch: 75/75] Total Loss: 1.4577238642507129\n",
      "Accuracy: 55.93%\n",
      "Accuracy: 2.27%\n"
     ]
    }
   ],
   "source": [
    "# Train network without `Y` values.\n",
    "\n",
    "# Create the datasets.\n",
    "train_dataset100_without_Y = DiabetesDataset(train_hundredth_precentile, transform=transform, drop_Y=True)\n",
    "val_dataset100_without_Y = DiabetesDataset(val_hundredth_precentile, transform=transform, drop_Y=True)\n",
    "\n",
    "# Create the dataloaders.\n",
    "train_loader100_without_Y = DataLoader(train_dataset100_without_Y, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader100_without_Y = DataLoader(val_dataset100_without_Y, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Create the neural network.\n",
    "classifer100_without_Y = DiabetesPrecentileClassifer(input_size=10, num_classes=100)\n",
    "\n",
    "# Train the network.\n",
    "train(classifer100_without_Y, train_loader100_without_Y, num_epochs=150, lr=0.001,\n",
    "      print_cost=True, print_stride=20)\n",
    "print(\"\\nREDUCED LEARNING RATE TO 0.0001\\n\")\n",
    "train(classifer100_without_Y, train_loader100_without_Y, num_epochs=75, lr=0.0001,\n",
    "      print_cost=True, print_stride=20)\n",
    "\n",
    "# Evaluate the network.\n",
    "print(f\"Accuracy: {evaluate(classifer100_without_Y, train_loader100_without_Y):.2%}\")\n",
    "print(f\"Accuracy: {evaluate(classifer100_without_Y, val_loader100_without_Y):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We experience much worse results, that is because the dataset is too small (around $4$ instances of each class) to successfully learn how to predict a class out of $100$ classes. It is preferable to use the tenth precentile as classes instead of the hundredth precentile, since the added accuracy in the `Y` prediction gained from the $100$ classes prediction is a lesser of a gain than the added overall accuracy of the $10$ classes prediction network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 POINTS BONNUS\n",
    "# Train a regression network on the dataset.\n",
    "# First, redfine the dataset to be a regression dataset.\n",
    "class DiabetesRegressionDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, transform: transforms.Compose | None = None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        x = row.drop('Y')\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        y = row['Y']\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "# Create a specific network architecture for regression.\n",
    "class DiabetesRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiabetesRegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = F.leaky_relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA for traininig.\n",
      "[epoch: 1/300] Total Loss: 23835.965689338234\n",
      "[epoch: 21/300] Total Loss: 3885.1588074448528\n",
      "[epoch: 41/300] Total Loss: 2980.1581778492646\n",
      "[epoch: 61/300] Total Loss: 2810.620428538603\n",
      "[epoch: 81/300] Total Loss: 2630.194403147978\n",
      "[epoch: 101/300] Total Loss: 2566.6053567325366\n",
      "[epoch: 121/300] Total Loss: 2558.6229348575366\n",
      "[epoch: 141/300] Total Loss: 2655.883910845588\n",
      "[epoch: 161/300] Total Loss: 2558.017380514706\n",
      "[epoch: 181/300] Total Loss: 2517.2215234375\n",
      "[epoch: 201/300] Total Loss: 2702.212099609375\n",
      "[epoch: 221/300] Total Loss: 2447.6083197380513\n",
      "[epoch: 241/300] Total Loss: 2310.2006071920955\n",
      "[epoch: 261/300] Total Loss: 2894.580680721507\n",
      "[epoch: 281/300] Total Loss: 2394.691056985294\n",
      "[epoch: 300/300] Total Loss: 2214.4571099494487\n",
      "\n",
      "REDUCED LEARNING RATE TO 0.0001\n",
      "\n",
      "Using CUDA for traininig.\n",
      "[epoch: 1/150] Total Loss: 2227.5455859375\n",
      "[epoch: 21/150] Total Loss: 2164.28366785386\n",
      "[epoch: 41/150] Total Loss: 2154.6327188648897\n",
      "[epoch: 61/150] Total Loss: 2149.1470846737134\n",
      "[epoch: 81/150] Total Loss: 2149.2427837775735\n",
      "[epoch: 101/150] Total Loss: 2175.764545611213\n",
      "[epoch: 121/150] Total Loss: 2142.0317578125\n",
      "[epoch: 141/150] Total Loss: 2146.3154897173713\n",
      "[epoch: 150/150] Total Loss: 2148.1795002297795\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHHCAYAAACiOWx7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQh0lEQVR4nO3deVxU5eIG8GdmYIZ1BpBNBAF3xaXSVFIzk0SzbpZlkrfILDWxMttvZXa999q1WzcrM+v+Um+3XCvLPXKBUtxQFDcyRUERUJYZ1gFm3t8fOEdGUIcCzhx5vp/PfGLOeefMe+Zg8/BuRyWEECAiIiKia1LLXQEiIiIiJWBoIiIiInIAQxMRERGRAxiaiIiIiBzA0ERERETkAIYmIiIiIgcwNBERERE5gKGJiIiIyAEMTUREREQOYGgiIlKQxx9/HBEREXJXg6hVYmgiagWWLFkClUoFlUqFX375pd5+IQTCwsKgUqlwzz33yFBDx1VVVWH+/Pm4+eabodfr4ePjg6ioKEyePBnHjx+Xu3pO44477pCu+ZWPbt26yV09IkVykbsCRNRy3Nzc8PXXX2Pw4MF225OSknD27FnodDqZaua4sWPHYuPGjYiLi8NTTz2F6upqHD9+HOvWrcNtt93GQFBHaGgo5s6dW2+7wWCQoTZEysfQRNSK3H333Vi1ahU+/PBDuLhc/uf/9ddfo2/fvrh48aKMtbu+vXv3Yt26dfj73/+Ov/zlL3b7Pv74YxQXF8tTMQeUlZXB09OzRd/TYDDgz3/+c6Nfd7W6CiFQWVkJd3f3312nyspKaLVaqNXs6CDl4W8tUSsSFxeHgoICJCYmStuqqqqwevVqPPLIIw2+xmq14oMPPkBUVBTc3NwQFBSEKVOmoKioyK7c999/j9GjRyMkJAQ6nQ4dO3bEnDlzYLFY7Mrdcccd6NmzJ44ePYphw4bBw8MD7dq1w7x5865b/5MnTwIABg0aVG+fRqNBmzZt7Lb98ssvuPXWW+Hm5oaOHTti0aJFmD17NlQqlVTm9OnTUKlUWLJkSb1jqlQqzJ49W3p+5swZTJs2DV27doW7uzvatGmDhx56CKdPn7Z7na07NCkpCdOmTUNgYCBCQ0Ol/Rs3bsSQIUPg6ekJb29vjB49GkeOHKn3/mvWrEHPnj3h5uaGnj174rvvvrvuZ9RYts/j6NGjeOSRR+Dr6yu1REZEROCee+7B5s2b0a9fP7i7u2PRokUAgFOnTuGhhx6Cn58fPDw8MHDgQKxfv97u2Nu3b4dKpcLy5cvxxhtvoF27dvDw8IDJZGry8yBqCWxpImpFIiIiEB0djWXLlmHUqFEAar/AjUYjxo8fjw8//LDea6ZMmYIlS5Zg4sSJePbZZ5GZmYmPP/4YBw4cwI4dO+Dq6gqgNih4eXlh5syZ8PLywtatWzFr1iyYTCa8++67dscsKirCyJEj8cADD2DcuHFYvXo1XnnlFfTq1UuqV0PCw8MBAF999RUGDRpk11p2pfT0dIwYMQIBAQGYPXs2ampq8NZbbyEoKKjRn5vN3r17sXPnTowfPx6hoaE4ffo0Fi5ciDvuuANHjx6Fh4eHXflp06YhICAAs2bNQllZGQDgyy+/RHx8PGJjY/HPf/4T5eXlWLhwIQYPHowDBw5Ig7x//PFHjB07Fj169MDcuXNRUFCAiRMn2oWv67FYLA22Hrq7u9drSXrooYfQuXNn/OMf/4AQQtqekZGBuLg4TJkyBU899RS6du2KvLw83HbbbSgvL8ezzz6LNm3aYOnSpfjTn/6E1atX4/7777c79pw5c6DVavHiiy/CbDZDq9U6fA5ETkUQ0Q1v8eLFAoDYu3ev+Pjjj4W3t7coLy8XQgjx0EMPiWHDhgkhhAgPDxejR4+WXvfzzz8LAOKrr76yO96mTZvqbbcdr64pU6YIDw8PUVlZKW0bOnSoACD++9//StvMZrMIDg4WY8eOveZ5WK1W6fVBQUEiLi5OLFiwQJw5c6Ze2TFjxgg3Nze7fUePHhUajUbU/V9fZmamACAWL15c7xgAxFtvvXXNc0xJSal3PrbPe/DgwaKmpkbaXlJSInx8fMRTTz1ld4zc3FxhMBjstt90002ibdu2ori4WNr2448/CgAiPDy84Q+oDtvn1NBjypQpUrm33npLABBxcXH1jhEeHi4AiE2bNtltnzFjhgAgfv75Z7tzi4yMFBEREcJisQghhNi2bZsAIDp06NDgZ0ekNOyeI2plxo0bh4qKCqxbtw4lJSVYt27dVbvmVq1aBYPBgLvuugsXL16UHn379oWXlxe2bdsmla07zqWkpAQXL17EkCFDUF5eXm9Wm5eXl91YG61Wi/79++PUqVPXrLtKpcLmzZvxt7/9Db6+vli2bBkSEhIQHh6Ohx9+WBrTZLFYsHnzZowZMwbt27eXXt+9e3fExsY6/Fldqe45VldXo6CgAJ06dYKPjw/2799fr/xTTz0FjUYjPU9MTERxcTHi4uLsPk+NRoMBAwZIn+f58+eRlpaG+Ph4u0Hbd911F3r06OFwfSMiIpCYmFjvMWPGjHplp06d2uAxIiMj631mGzZsQP/+/e0mFHh5eWHy5Mk4ffo0jh49alc+Pj7+D42DInIW7J4jamUCAgIQExODr7/+GuXl5bBYLHjwwQcbLHvixAkYjUYEBgY2uD8/P1/6+ciRI3jjjTewdevWemNWjEaj3fPQ0FC7cUUA4Ovri0OHDl23/jqdDq+//jpef/11nD9/HklJSZg/fz5WrlwJV1dX/O9//8OFCxdQUVGBzp0713t9165dsWHDhuu+T0MqKiowd+5cLF68GOfOnbPrxrryHIHawFHXiRMnAAB33nlng8fX6/UAasdOAbhq/RsKaA3x9PRETEyMQ2WvrOu1tp85cwYDBgyot7179+7S/p49e1732ERKw9BE1Ao98sgjeOqpp5Cbm4tRo0bBx8enwXJWqxWBgYH46quvGtwfEBAAACguLsbQoUOh1+vx17/+FR07doSbmxv279+PV155BVar1e51dVtf6qobQhzRtm1bjB8/HmPHjkVUVBRWrlzZ4IDua7kyvNlcOYAdAJ555hksXrwYM2bMQHR0NAwGA1QqFcaPH1/vHAHUa12xlfnyyy8RHBxcr/y1xmg1t6u1BDVFCxFbmehGwdBE1Ardf//9mDJlCnbt2oUVK1ZctVzHjh3x008/YdCgQdf84tu+fTsKCgrw7bff4vbbb5e2Z2ZmNmm9r8bV1RW9e/fGiRMncPHiRQQEBMDd3V1q2akrIyPD7rmvry8A1FuuwNbaU9fq1asRHx+P9957T9pWWVnp8FIHHTt2BAAEBgZeswXINuDdkfrLITw8vMF62LphbfUnutFwTBNRK+Tl5YWFCxdi9uzZuPfee69abty4cbBYLJgzZ069fTU1NVJYsLUc1W0pqqqqwieffNKk9T5x4gSysrLqbS8uLkZKSgp8fX0REBAAjUaD2NhYrFmzxq78sWPHsHnzZrvX6vV6+Pv7Izk52W57Q3XXaDT1WsM++uijBlulGhIbGwu9Xo9//OMfqK6urrf/woULAGpb0G666SYsXbrUrtsvMTGx3nghOdx9993Ys2cPUlJSpG1lZWX47LPPEBER0ahxV0RKwpYmolYqPj7+umWGDh2KKVOmYO7cuUhLS8OIESPg6uqKEydOYNWqVZg/fz4efPBB3HbbbfD19UV8fDyeffZZqFQqfPnll43ubruegwcP4pFHHsGoUaMwZMgQ+Pn54dy5c1i6dClycnLwwQcfSAHu7bffxqZNmzBkyBBMmzYNNTU1+OijjxAVFVVv7NSTTz6Jd955B08++ST69euH5ORk/Prrr/Xe/5577sGXX34Jg8GAHj16ICUlBT/99FO99aGuRq/XY+HChXj00Udxyy23YPz48QgICEBWVhbWr1+PQYMG4eOPPwYAzJ07F6NHj8bgwYPxxBNPoLCwUKp/aWmpQ+9nNBrxv//9r8F9v2fRS5tXX31VWrbi2WefhZ+fH5YuXYrMzEx88803XLiSblyyzt0johZRd8mBa7lyyQGbzz77TPTt21e4u7sLb29v0atXL/Hyyy+LnJwcqcyOHTvEwIEDhbu7uwgJCREvv/yy2Lx5swAgtm3bJpUbOnSoiIqKqvce8fHx151Kn5eXJ9555x0xdOhQ0bZtW+Hi4iJ8fX3FnXfeKVavXl2vfFJSkujbt6/QarWiQ4cO4tNPP5Wm2NdVXl4uJk2aJAwGg/D29hbjxo0T+fn59ZYcKCoqEhMnThT+/v7Cy8tLxMbGiuPHj4vw8HARHx8vlbve571t2zYRGxsrDAaDcHNzEx07dhSPP/642Ldvn125b775RnTv3l3odDrRo0cP8e233zr0OQlx7SUH6p6/7fO4cOFCvWNc7fdBCCFOnjwpHnzwQeHj4yPc3NxE//79xbp16+qdJwCxatWq69aXSAlUQjTxn4JERE5s9uzZePvtt5u8FYyIbnxsQyUiIiJyAEMTERERkQMYmoiIiIgcwDFNRERERA5gSxMRERGRAxiaiIiIiBzAxS2biNVqRU5ODry9va96LysiIiJyLkIIlJSUICQk5LoLszI0NZGcnByEhYXJXQ0iIiL6HbKzsxEaGnrNMgxNTcTb2xtA7Yeu1+tlrg0RERE5wmQyISwsTPoevxaGpiZi65LT6/UMTURERArjyNAaDgQnIiIicgBDExEREZEDGJqIiIiIHMDQREREROQAhiYiIiIiBzA0ERERETmAoYmIiIjIAQxNRERERA5gaCIiIiJyAEMTERERkQMYmoiIiIgcwNBERERE5ADesNfJlVfVoLCsCloXNQK93eSuDhERUavFliYnl3g0D4P/uQ3Pr0iTuypEREStGkOTk1OrVAAAi1XIXBMiIqLWjaHJyWnUtaHJapW5IkRERK0cQ5OTu5SZYBVsaSIiIpITQ5OTk7rnGJqIiIhkxdDk5C53zzE0ERERyYmhycmp1WxpIiIicgYMTU5OI82ek7kiRERErRxDk5Nj9xwREZFzYGhychwITkRE5BwYmpwcW5qIiIicA0OTk+M6TURERM6BocnJcfYcERGRc2BocnK22XO8jQoREZG8GJqcnG1ME2/YS0REJC+GJifH2XNERETOgaHJyXH2HBERkXNgaHJymktXiC1NRERE8mJocnJS9xxbmoiIiGTF0OTkbKGJDU1ERETyYmhycpw9R0RE5BwYmpwcF7ckIiJyDgxNTu7y4pYMTURERHJiaHJyas6eIyIicgoMTU5OU2cguGBwIiIikg1Dk5OzDQQHOBiciIhITgxNTk5dNzSxpYmIiEg2DE1OzrZOEwBYrTJWhIiIqJVjaHJymrqhiS1NREREsmFocnLqOleI3XNERETyYWhycnYtTRwITkREJBuGJifH2XNERETOgaHJyalUKtgam9g9R0REJB+GJgW4fCsVmStCRETUijE0KQBv2ktERCQ/hiYFsA1r4kBwIiIi+TA0KYDUPceWJiIiItkwNCmA1D3HliYiIiLZMDQpgG3ZAbY0ERERyYehSQFs3XMWzp4jIiKSDUOTArB7joiISH4MTQrAgeBERETyY2hSAA1bmoiIiGTH0KQAvI0KERGR/BiaFMDW0iQYmoiIiGTD0KQAnD1HREQkP4YmBeDsOSIiIvkxNCkAZ88RERHJj6FJAdjSREREJD+GJgXQXLpKnD1HREQkH4YmBZC659jSREREJBuGJgVQqdg9R0REJDeGJgWwrdPEgeBERETyYWhSgMuz52SuCBERUSvG0KQAattAcKYmIiIi2TA0KQC754iIiOQna2iaO3cubr31Vnh7eyMwMBBjxoxBRkaGXZnKykokJCSgTZs28PLywtixY5GXl2dXJisrC6NHj4aHhwcCAwPx0ksvoaamxq7M9u3bccstt0Cn06FTp05YsmRJvfosWLAAERERcHNzw4ABA7Bnz54mP+ffQ82B4ERERLKTNTQlJSUhISEBu3btQmJiIqqrqzFixAiUlZVJZZ5//nmsXbsWq1atQlJSEnJycvDAAw9I+y0WC0aPHo2qqirs3LkTS5cuxZIlSzBr1iypTGZmJkaPHo1hw4YhLS0NM2bMwJNPPonNmzdLZVasWIGZM2firbfewv79+9GnTx/ExsYiPz+/ZT6Ma9BwcUsiIiL5CSeSn58vAIikpCQhhBDFxcXC1dVVrFq1Sipz7NgxAUCkpKQIIYTYsGGDUKvVIjc3VyqzcOFCodfrhdlsFkII8fLLL4uoqCi793r44YdFbGys9Lx///4iISFBem6xWERISIiYO3euQ3U3Go0CgDAajY086+t7YvEeEf7KOrF8z5kmPzYREVFr1pjvb6ca02Q0GgEAfn5+AIDU1FRUV1cjJiZGKtOtWze0b98eKSkpAICUlBT06tULQUFBUpnY2FiYTCYcOXJEKlP3GLYytmNUVVUhNTXVroxarUZMTIxU5kpmsxkmk8nu0Vwur9PUbG9BRERE1+E0oclqtWLGjBkYNGgQevbsCQDIzc2FVquFj4+PXdmgoCDk5uZKZeoGJtt+275rlTGZTKioqMDFixdhsVgaLGM7xpXmzp0Lg8EgPcLCwn7fiTuAt1EhIiKSn9OEpoSEBBw+fBjLly+XuyoOee2112A0GqVHdnZ2s72XbUyTYGgiIiKSjYvcFQCA6dOnY926dUhOTkZoaKi0PTg4GFVVVSguLrZrbcrLy0NwcLBU5spZbrbZdXXLXDnjLi8vD3q9Hu7u7tBoNNBoNA2WsR3jSjqdDjqd7vedcCNx9hwREZH8ZG1pEkJg+vTp+O6777B161ZERkba7e/bty9cXV2xZcsWaVtGRgaysrIQHR0NAIiOjkZ6errdLLfExETo9Xr06NFDKlP3GLYytmNotVr07dvXrozVasWWLVukMnLi7DkiIiL5ydrSlJCQgK+//hrff/89vL29pfFDBoMB7u7uMBgMmDRpEmbOnAk/Pz/o9Xo888wziI6OxsCBAwEAI0aMQI8ePfDoo49i3rx5yM3NxRtvvIGEhASpJWjq1Kn4+OOP8fLLL+OJJ57A1q1bsXLlSqxfv16qy8yZMxEfH49+/fqhf//++OCDD1BWVoaJEye2/Adzhcu3UWFoIiIikk2zz+W7BgANPhYvXiyVqaioENOmTRO+vr7Cw8ND3H///eL8+fN2xzl9+rQYNWqUcHd3F/7+/uKFF14Q1dXVdmW2bdsmbrrpJqHVakWHDh3s3sPmo48+Eu3btxdarVb0799f7Nq1y+Fzac4lB15YmSbCX1knPtn2W5Mfm4iIqDVrzPe3Sgg2XzQFk8kEg8EAo9EIvV7fpMd+ZfUhrNiXjZdiuyJhWKcmPTYREVFr1pjvb6eZPUdXxxv2EhERyY+hSQE4e46IiEh+DE0KwHWaiIiI5MfQpABSSxNDExERkWwYmhTg8jpNMleEiIioFWNoUgBbaOI6TURERPJhaFIADgQnIiKSH0OTAmi45AAREZHsGJoUQM3bqBAREcmOoUkB2D1HREQkP4YmBeBAcCIiIvkxNCmAFJq45AAREZFsGJoUgItbEhERyY+hSQFss+esHNNEREQkG4YmBWBLExERkfwYmhTg8m1UGJqIiIjkwtCkAFyniYiISH4MTQqgZksTERGR7BiaFEAjLW4pc0WIiIhaMYYmBbDNnhPsniMiIpINQ5MCcPYcERGR/BiaFICz54iIiOTH0KQAvPccERGR/BiaFEDqnmNLExERkWwYmhRAWqeJs+eIiIhkw9CkALbZcxwITkREJB+GJgVg9xwREZH8GJoUwDYQnOs0ERERyYehSQGk26gwNBEREcmGoUkBeBsVIiIi+TE0KYC0ThPHNBEREcmGoUkBeBsVIiIi+TE0KcClhia2NBEREcmIoUkBNBwITkREJDuGJgVQ84a9REREsmNoUgCNigPBiYiI5MbQpADS7DlmJiIiItkwNCkAZ88RERHJj6FJAbhOExERkfwYmhRAc+kqsaWJiIhIPgxNCqBScfYcERGR3BiaFICz54iIiOTH0KQAXNySiIhIfgxNCqCWBoLLXBEiIqJWjKFJAaTuObY0ERERyYahSQHUnD1HREQkO4YmBbC1NAkBCAYnIiIiWTA0KYBtIDjAZQeIiIjkwtCkALZ1mgB20REREcmFoUkB6rY0cQYdERGRPBiaFEDDliYiIiLZMTQpgLrOVeKYJiIiInkwNClA3ZYm3kqFiIhIHgxNCmA3pondc0RERLJgaFIAlUoFW2MTxzQRERHJg6FJIaRbqXD2HBERkSwYmhRCfSk0saWJiIhIHgxNCmGbQceB4ERERPJgaFIIW/cclxwgIiKSB0OTQqjV7J4jIiKSE0OTQtiWHWD3HBERkTwYmhRCmj3HzERERCQLhiaFkLrnmJqIiIhkwdCkEJdbmhiaiIiI5MDQpBC2O6mwpYmIiEgeDE0KwdlzRERE8pI1NCUnJ+Pee+9FSEgIVCoV1qxZY7f/8ccfv3TftcuPkSNH2pUpLCzEhAkToNfr4ePjg0mTJqG0tNSuzKFDhzBkyBC4ubkhLCwM8+bNq1eXVatWoVu3bnBzc0OvXr2wYcOGJj/fP4Kz54iIiOQla2gqKytDnz59sGDBgquWGTlyJM6fPy89li1bZrd/woQJOHLkCBITE7Fu3TokJydj8uTJ0n6TyYQRI0YgPDwcqampePfddzF79mx89tlnUpmdO3ciLi4OkyZNwoEDBzBmzBiMGTMGhw8fbvqT/p24uCUREZG8XOR881GjRmHUqFHXLKPT6RAcHNzgvmPHjmHTpk3Yu3cv+vXrBwD46KOPcPfdd+Nf//oXQkJC8NVXX6GqqgpffPEFtFotoqKikJaWhvfff18KV/Pnz8fIkSPx0ksvAQDmzJmDxMREfPzxx/j000+b8Ix/P3bPERERycvpxzRt374dgYGB6Nq1K55++mkUFBRI+1JSUuDj4yMFJgCIiYmBWq3G7t27pTK33347tFqtVCY2NhYZGRkoKiqSysTExNi9b2xsLFJSUprz1BrF1tLEzERERCQPWVuarmfkyJF44IEHEBkZiZMnT+Ivf/kLRo0ahZSUFGg0GuTm5iIwMNDuNS4uLvDz80Nubi4AIDc3F5GRkXZlgoKCpH2+vr7Izc2VttUtYztGQ8xmM8xms/TcZDL9oXO9Hq7TREREJC+nDk3jx4+Xfu7Vqxd69+6Njh07Yvv27Rg+fLiMNQPmzp2Lt99+u8XeT3OpTZDdc0RERPJw+u65ujp06AB/f3/89ttvAIDg4GDk5+fblampqUFhYaE0Dio4OBh5eXl2ZWzPr1fmamOpAOC1116D0WiUHtnZ2X/s5K5DreLsOSIiIjkpKjSdPXsWBQUFaNu2LQAgOjoaxcXFSE1Nlcps3boVVqsVAwYMkMokJyejurpaKpOYmIiuXbvC19dXKrNlyxa790pMTER0dPRV66LT6aDX6+0ezUnN2XNERESykjU0lZaWIi0tDWlpaQCAzMxMpKWlISsrC6WlpXjppZewa9cunD59Glu2bMF9992HTp06ITY2FgDQvXt3jBw5Ek899RT27NmDHTt2YPr06Rg/fjxCQkIAAI888gi0Wi0mTZqEI0eOYMWKFZg/fz5mzpwp1eO5557Dpk2b8N577+H48eOYPXs29u3bh+nTp7f4Z3I10jpN7J4jIiKSh5DRtm3bBIB6j/j4eFFeXi5GjBghAgIChKurqwgPDxdPPfWUyM3NtTtGQUGBiIuLE15eXkKv14uJEyeKkpISuzIHDx4UgwcPFjqdTrRr106888479eqycuVK0aVLF6HVakVUVJRYv359o87FaDQKAMJoNDb+g3DAQwt3ivBX1ol1B3Oa5fhEREStUWO+v1VCsOmiKZhMJhgMBhiNxmbpqhv/WQp2nSrEh3E34099Qpr8+ERERK1RY76/FTWmqTXjbVSIiIjkxdCkENLsOTYMEhERyYKhSSE0XNySiIhIVgxNCsGWJiIiInkxNCnE5XWaZK4IERFRK8XQpBC8jQoREZG8GJoUgrPniIiI5MXQpBC8jQoREZG8GJoUgrdRISIikhdDk0JoOHuOiIhIVgxNCqFWc/YcERGRnBiaFOJSZmJLExERkUwYmhSCK4ITERHJi6FJITh7joiISF6NCk3z5s1DRUWF9HzHjh0wm83S85KSEkybNq3pakcSzp4jIiKSV6NC02uvvYaSkhLp+ahRo3Du3DnpeXl5ORYtWtR0tSMJW5qIiIjk1ajQJK5o5bjyOTUfaUwTP3MiIiJZcEyTQthCEzMTERGRPBiaFOJS7xy754iIiGTi0tgX/Oc//4GXlxcAoKamBkuWLIG/vz8A2I13oqal4ZgmIiIiWTUqNLVv3x6ff/659Dw4OBhffvllvTLU9Dh7joiISF6NCk2nT59upmrQ9XD2HBERkbw4pkkh2NJEREQkr0aFppSUFKxbt85u23//+19ERkYiMDAQkydPtlvskpoOb6NCREQkr0aFpr/+9a84cuSI9Dw9PR2TJk1CTEwMXn31VaxduxZz585t8kpS3e45mStCRETUSjUqNKWlpWH48OHS8+XLl2PAgAH4/PPPMXPmTHz44YdYuXJlk1eSAM2lK8XuOSIiInk0KjQVFRUhKChIep6UlIRRo0ZJz2+99VZkZ2c3Xe1IYmtpYmgiIiKSR6NCU1BQEDIzMwEAVVVV2L9/PwYOHCjtLykpgaura9PWkABw9hwREZHcGhWa7r77brz66qv4+eef8dprr8HDwwNDhgyR9h86dAgdO3Zs8koSZ88RERHJrVHrNM2ZMwcPPPAAhg4dCi8vLyxZsgRarVba/8UXX2DEiBFNXkkC1Jw9R0REJKtGhSZ/f38kJyfDaDTCy8sLGo3Gbv+qVavg7e3dpBWkWhrOniMiIpJVo0LTE0884VC5L7744ndVhq6Os+eIiIjk1ajQtGTJEoSHh+Pmm2+G4Jd3i+JAcCIiInk1KjQ9/fTTWLZsGTIzMzFx4kT8+c9/hp+fX3PVjergQHAiIiJ5NWr23IIFC3D+/Hm8/PLLWLt2LcLCwjBu3Dhs3ryZLU/NjOs0ERERyavRN+zV6XSIi4tDYmIijh49iqioKEybNg0REREoLS1tjjoSOHuOiIhIbo0OTXYvVquhUqkghIDFYmmqOlEDbLPnrJw9R0REJItGhyaz2Yxly5bhrrvuQpcuXZCeno6PP/4YWVlZ8PLyao46Ei7PnrOwe46IiEgWjRoIPm3aNCxfvhxhYWF44oknsGzZMvj7+zdX3agOjmkiIiKSV6NC06effor27dujQ4cOSEpKQlJSUoPlvv322yapHF0mhSaOaSIiIpJFo0LTY489BtWlL29qWbYlB9g9R0REJI9GL25J8rDNnuNAcCIiInn8odlz1HIuZSaOaSIiIpIJQ5NCaHgbFSIiIlkxNCmEmrdRISIikhVDk0JcXnJA5ooQERG1UgxNCiEtbsnUREREJAuGJoVQc0wTERGRrBiaFMK2TpPgmCYiIiJZMDQphNTSxNBEREQkC4YmhbjcPSdzRYiIiFophiaFYPccERGRvBiaFMK2Iji754iIiOTB0KQQtsUtOXuOiIhIHgxNCmG7jQobmoiIiOTB0KQQXKeJiIhIXgxNCqG2rQjOpiYiIiJZMDQpBGfPERERyYuhSSE07J4jIiKSFUOTQqguhSarYGsTERGRHBiaFMLWPQfUBiciIiJqWQxNCmHrngMAK1uaiIiIWhxDk0Ko6lwpjmsiIiJqeQxNCsGWJiIiInkxNCkExzQRERHJi6FJIeo0NLF7joiISAYMTQph1z3H0ERERNTiZA1NycnJuPfeexESEgKVSoU1a9bY7RdCYNasWWjbti3c3d0RExODEydO2JUpLCzEhAkToNfr4ePjg0mTJqG0tNSuzKFDhzBkyBC4ubkhLCwM8+bNq1eXVatWoVu3bnBzc0OvXr2wYcOGJj/fP8K+e46hiYiIqKXJGprKysrQp08fLFiwoMH98+bNw4cffohPP/0Uu3fvhqenJ2JjY1FZWSmVmTBhAo4cOYLExESsW7cOycnJmDx5srTfZDJhxIgRCA8PR2pqKt59913Mnj0bn332mVRm586diIuLw6RJk3DgwAGMGTMGY8aMweHDh5vv5BtJpVJJXXS8/xwREZEMhJMAIL777jvpudVqFcHBweLdd9+VthUXFwudTieWLVsmhBDi6NGjAoDYu3evVGbjxo1CpVKJc+fOCSGE+OSTT4Svr68wm81SmVdeeUV07dpVej5u3DgxevRou/oMGDBATJkyxeH6G41GAUAYjUaHX9NYHV5bL8JfWSfOF1c023sQERG1Jo35/nbaMU2ZmZnIzc1FTEyMtM1gMGDAgAFISUkBAKSkpMDHxwf9+vWTysTExECtVmP37t1Smdtvvx1arVYqExsbi4yMDBQVFUll6r6PrYztfRpiNpthMpnsHs1NI91KhS1NRERELc1pQ1Nubi4AICgoyG57UFCQtC83NxeBgYF2+11cXODn52dXpqFj1H2Pq5Wx7W/I3LlzYTAYpEdYWFhjT7HR1JeuFmfPERERtTynDU3O7rXXXoPRaJQe2dnZzf6earY0ERERycZpQ1NwcDAAIC8vz257Xl6etC84OBj5+fl2+2tqalBYWGhXpqFj1H2Pq5Wx7W+ITqeDXq+3ezQ3W/ccW5qIiIhantOGpsjISAQHB2PLli3SNpPJhN27dyM6OhoAEB0djeLiYqSmpkpltm7dCqvVigEDBkhlkpOTUV1dLZVJTExE165d4evrK5Wp+z62Mrb3cRZqta2lSeaKEBERtUKyhqbS0lKkpaUhLS0NQO3g77S0NGRlZUGlUmHGjBn429/+hh9++AHp6el47LHHEBISgjFjxgAAunfvjpEjR+Kpp57Cnj17sGPHDkyfPh3jx49HSEgIAOCRRx6BVqvFpEmTcOTIEaxYsQLz58/HzJkzpXo899xz2LRpE9577z0cP34cs2fPxr59+zB9+vSW/kiuybZUE7vniIiIZNACs/muatu2bQJAvUd8fLwQonbZgTfffFMEBQUJnU4nhg8fLjIyMuyOUVBQIOLi4oSXl5fQ6/Vi4sSJoqSkxK7MwYMHxeDBg4VOpxPt2rUT77zzTr26rFy5UnTp0kVotVoRFRUl1q9f36hzaYklB/rO+VGEv7JOHM1pvvcgIiJqTRrz/a0Sgs0WTcFkMsFgMMBoNDbb+Kb+f/8J+SVmrH92MKJCDM3yHkRERK1JY76/nXZME9Vnu5WK1SpzRYiIiFohhiYFsS05wNuoEBERtTyGJgWxLW7JgeBEREQtj6FJQaTbqHDNASIiohbH0KQgai5uSUREJBuGJgXh4pZERETyYWhSEA3vPUdERCQbhiYFuZSZ2D1HREQkA4YmBbGt08QlB4iIiFoeQ5OC2EITF3EnIiJqeQxNCnJ59pzMFSEiImqFGJoURM0xTURERLJhaFIQds8RERHJh6FJQXjvOSIiIvkwNCkIVwQnIiKSD0OTglzunpO5IkRERK0QQ5OC2G6jwpYmIiKilsfQpCDS7Dk2NREREbU4hiYFsd17jrPniIiIWh5Dk4Jc7p6TuSJEREStEEOTgmi45AAREZFsGJoURH3palk5EJyIiKjFMTQpiG2dJitbmoiIiFocQ5OCaLjkABERkWwYmhSELU1ERETyYWhSkMuhSeaKEBERtUIMTQqiuXS12D1HRETU8hiaFERqaWJoIiIianEMTQpiW9ySmYmIiKjlMTQpCBe3JCIikg9Dk4LYlhxg9xwREVHLY2hSkEsNTVxygIiISAYMTQrC7jkiIiL5MDQpCLvniIiI5MPQpCAqW0uTVeaKEBERtUIMTQpiW9ySY5qIiIhaHkOTgmh47zkiIiLZMDQpyOXuOYYmIiKilsbQpCAarghOREQkG4YmBeHsOSIiIvkwNCmImus0ERERyYahSUHUXBGciIhINgxNCsLuOSIiIvkwNCnI5e45mStCRETUCjE0KQi754iIiOTD0KQg7J4jIiKSD0OTgqjVXNySiIhILgxNCqLmbVSIiIhkw9CkIJfvPSdzRYiIiFohhiYFYfccERGRfBiaFERz6Wqxe46IiKjlMTQpCMc0ERERyYehSUFsoamGq1sSERG1OIYmBQn01gEAzhZVyFwTIiKi1oehSUG6h+gBAOeKK1BcXiVzbYiIiFoXhiYF0bu5IszPHQBw9LxJ5toQERG1LgxNCtOjbW1rU1LGBdRYrDLXhoiIqPVgaFKYqBADAGBR8im8/t1hmWtDRETUejA0KcygTv7Sz0fOG2WsCRERUevC0KQwfcN98Y/7ewEAys0WmWtDRETUejA0KdBNYT4AgBJzjbwVISIiakUYmhTI280FAFBaydBERETUUhiaFMhLVxuaKqotnEFHRETUQhiaFMjzUmgCgDKOayIiImoRDE0KpHVRQ+dSe+lKzNUy14aIiKh1YGhSKGlcEweDExERtQinDk2zZ8+GSqWye3Tr1k3aX1lZiYSEBLRp0wZeXl4YO3Ys8vLy7I6RlZWF0aNHw8PDA4GBgXjppZdQU2MfNLZv345bbrkFOp0OnTp1wpIlS1ri9P4QWxcdB4MTERG1DKcOTQAQFRWF8+fPS49ffvlF2vf8889j7dq1WLVqFZKSkpCTk4MHHnhA2m+xWDB69GhUVVVh586dWLp0KZYsWYJZs2ZJZTIzMzF69GgMGzYMaWlpmDFjBp588kls3ry5Rc+zsWyDwbnsABERUctQCSGE3JW4mtmzZ2PNmjVIS0urt89oNCIgIABff/01HnzwQQDA8ePH0b17d6SkpGDgwIHYuHEj7rnnHuTk5CAoKAgA8Omnn+KVV17BhQsXoNVq8corr2D9+vU4fPjyLUnGjx+P4uJibNq0yeG6mkwmGAwGGI1G6PX6P3biDnh4UQp2ZxYCAP42pif+PDC82d+TiIjoRtOY72+nb2k6ceIEQkJC0KFDB0yYMAFZWVkAgNTUVFRXVyMmJkYq261bN7Rv3x4pKSkAgJSUFPTq1UsKTAAQGxsLk8mEI0eOSGXqHsNWxnYMZ2Ub0wQAb6w5zLFNREREzcypQ9OAAQOwZMkSbNq0CQsXLkRmZiaGDBmCkpIS5ObmQqvVwsfHx+41QUFByM3NBQDk5ubaBSbbftu+a5UxmUyoqKi4at3MZjNMJpPdoyV51Vl2AAB+SMtp0fcnIiJqbVyuX0Q+o0aNkn7u3bs3BgwYgPDwcKxcuRLu7u4y1gyYO3cu3n77bdne38vN/tJ9d+AsHhnQXqbaEBER3ficuqXpSj4+PujSpQt+++03BAcHo6qqCsXFxXZl8vLyEBwcDAAIDg6uN5vO9vx6ZfR6/TWD2WuvvQaj0Sg9srOz/+jpNYqXztXu+aGzRlRzdXAiIqJmo6jQVFpaipMnT6Jt27bo27cvXF1dsWXLFml/RkYGsrKyEB0dDQCIjo5Geno68vPzpTKJiYnQ6/Xo0aOHVKbuMWxlbMe4Gp1OB71eb/doSd5XtDSZa6w4fr6kRetARETUmjh1aHrxxReRlJSE06dPY+fOnbj//vuh0WgQFxcHg8GASZMmYebMmdi2bRtSU1MxceJEREdHY+DAgQCAESNGoEePHnj00Udx8OBBbN68GW+88QYSEhKg0+kAAFOnTsWpU6fw8ssv4/jx4/jkk0+wcuVKPP/883Ke+nXVWC5Peuwf4QcAOJBdJFd1iIiIbnhOPabp7NmziIuLQ0FBAQICAjB48GDs2rULAQEBAIB///vfUKvVGDt2LMxmM2JjY/HJJ59Ir9doNFi3bh2efvppREdHw9PTE/Hx8fjrX/8qlYmMjMT69evx/PPPY/78+QgNDcV//vMfxMbGtvj5NkZBmVn6ObpjG+w5XYhZ3x9BYVkVpg/rBBeNU+dhIiIixXHqdZqUpKXXadqQfh7TvtoPT60GS57oj4c+vbxEwthbQvHeuD7NXgciIiKla8z3N0NTE2np0GS1CiQey0PvUAPaGtyReqYIezIL8c9Nx6FSAUkvDkP7Nh7NXg8iIiIlu6EWt6SGqdUqxEYFo62hdoZf33BfPH1HR9zeJQBCAH9bfxTF5VUy15KIiOjGwdB0g5l6ewcAwI9H8xC/eC+sVjYkEhERNQWGphvMbZ388d8n+sNL54KD2cVYe4grhRMRETUFhqYb0O1dAjB1aG2L06zvj+B4bsve4oWIiOhGxNB0g3pySAfc3N4HxopqPLF4LwrLOL6JiIjoj2BoukG5uWqw5PH+iPT3RI6xEuM/S8GuUwUoqawGJ0wSERE1HpccaCItveSAozJySxD3+S67lqZ7+4Tgo7ibZawVERGRc+CSAyTpGuyNLTOH4tGB4dK2dYdykG+qlLFWREREysPQ1Ar4emoxZ0xPHJw1At2CvSEEcPeHv+BgdrHcVSMiIlIMhqZWxODhikcGtAcAXCw1Y9LSvaistshcKyIiImVgaGplHrglFCN6BAEALpZWYcXebJlrREREpAwMTa2Ml84Fnz3WD3PuiwIAzFl3FF/tPiNzrYiIiJwfQ1Mr9fCt7TG6d1vUWAXmrDvKdZyIiIiug6GpldK6qPFx3M3o1c6AymorFiWf5PpNRERE18DQ1IqpVCpMuXS7lUVJp/DS6kO8wS8REdFVMDS1cqN7tcVzwzvDRa3C6tSz+OCnX+WuEhERkVNiaGrlVCoVnr+rC/5xfy8AwIdbf0PEq+sxY/kBWNjqREREJGFoIgDAuFvDpK46AFiTloPOr2/ACysPIr+Eq4cTERExNJHkldhumDe2N0b3agsAsArgm/1n8fCiXSivqpG5dkRERPLiDXubiLPesPf3OphdjNMFZXhn43GcN1bi3j4heG54J4S38YSrxvGsLYTAyn3ZCNK74Y6ugc1YYyIiosZrzPc3Q1MTudFCk03yrxfw2Bd7pOcB3jo8N7wzJgxoD5VKdd3Xbz2ehyeW7AMA7H/zLvh5aputrkRERI3VmO9vds/RNd3eJQBLn+iPqBA9tC5qXCgx4401h/Hk0n1I+vXCNV8rhMD8Lb9Jz1en8pYtRH/Eb/mlMFVWy10NolaLLU1N5EZtaaqrqsaKz38+hXc3Z0jb7uoRhIf7haFnOwOCDW4wlldjwv/tQgd/L/x5YDjGLUqRyoYY3PDDM4Ph5qqBq0YFnYtGjtNo0P6sIpgqqtmFSE7rt/wSxLyfjK5B3tj8/O1yV4fohsHuORm0htBkk37WiG/2n8X/dp1BzaVlCVQqYHAnf7i7avDj0TwAgFajRpXFij/1CcGB7CJkF1ZIx+ga5I0Nzw2BRn39Lr7mZqqsxoC/b4G5xoJtL96B8DaecleJqJ7Pkk/iHxuOAwCOzxkJN1fn+aODSMnYPUfNqleoAbP/FIUNzw1BbFQQOgV6QQjg5xMXpcAEAFUWKwBg0uBILJnYH23qjGfKyCvBtuP5+Hb/WWzLyIcQ4qq3camqsaKqxtps57Mx/Twqqi2wCmB7xrW7HInkUvefR7c3N3EhWiIZuMhdAVKuLkHeWPRoPwDAmYIyrE49i/WHziPC3xO/5pXgbFEFYroHoneoASqVCmsSBuGNNYelsVBP/nef3fGiQvSYMrQjfs0tgY+HKx6LjsCipJP4NOkk2vq4Y+30wXDX1v/r+te8ElTVWNE5yAsalQoul2b3lZprYBUCejfXa57HN/vPST8n/XoB8bdF/JGPhahZnDfar5f2wU8n8MydnZ2itZaotWD3XBNpTd1zjrBaBaqt1gbHLZ0pKMPw95Kkrj1HtTW44c8Dw9HOxx3tfN0RrHfD5iO5mLvxuLR6eXgbD/wwfTBqLFbc+9EvqLJYseG5IQj0dmvwmNmF5Rgyb5v03N1VgwOz7vrDXR+bDufi5IVSPD20I9S/80vNYhWotlj/UF1SzxRiQ3ouXortesN151isolUFhsn/3WfXkgsAPz5/O7oEectUI6IbQ2O+v9nSRM1CrVZBp274Szq8jSe+efo2/JpXgpvCfLDndCEKS6twLNeEk/llcHVR4WR+GSqqLQCAPmE+OJhdjPPGSrtB6A05U1COhxelQKVSIefSX+Zvrz2KeWN7I/VMEbzdXOCiVqOyxoJbI/yw5kBtK1N0hzY4XVCG88ZKbDuej1GXFvh0lNUqoFarYCyvxn9+OYWPttbOGuwa5I2hXQMatbaVzbPLD2DrsXyse3YwOgZ4AQAWbPsNPx7JxeeP9UOgvjYI/pZfih2/XcSoXsEI9HZDZbUFF0vNCPX1wNiFtQPx3VzVeCm2W6Pr4KyW7MjEPzdl4OFbwzCiRxBe+fYQ3hzdAyOigqUyQggcOmtE12DvGyIwXtnSBAAHsoocDk2mymo8/b9URLTxxJz7ev7uME/UmrGlqYmwpalpGcur8c3+s/D31mF0r7Z4Y006coor0cZTixxjBc4VV+B8cSUCvXV4elgn/Kl3CJJPXMAzyw40eDyVyn5MCAAM7OCHY+dLYKyoxr8e6oOTF0qxcPtJtPNxx9ShHWCxCozv3x5/+TYd2UXl6ODvhVxTJcbcHII/9WkHjVqFymoLpv4vFb/ll+Lzx/rh+RVpOJ5bYvc+rhoV/Dy18HZzxeeP9UOkf/2B5geyinDqQhnG3Fx73NQzRRi7cCeA2jFhb97TA2nZxRizYAcAIGFYRykE3T3/Zxw9b4JWo8aG54bgo60nsPZgDj4YfzOevfR59AnzwfcJg/7QNVl3KAcLt5/Evx++6apf1DUWK47nliDQWyeFuobkGiuxOjUbjwwIb/TaXT8dzavXtWtz+p3R0s+2gdNP39ERr4y8dmDMKa7Aa9+mY9LgSNzeJaBR9WkpfeckoqCsCk8MisSJ/BL8fOIi4vqHYe4DvR16/ewfjmDJztMAgOnDOuHF2K7NWFsi5eDsORkwNLU8q1VApYLdIpvbMvKReDQP3joX3NsnBBm5JXjz+8Mor7KgrcENF0rM9boFQ33dsWnG7cg1ViLm/SSH3rtrkDd6hRpwNMeEo+dN9fY/2DcUq1PP1tvuqdXgTze1w2PR4Wjv54GMvBIs35OF1alnYRXAyyO7wmoV+NePlwf5Bul1mHlXF7yz8TiKymvX6Gnv54Gkl+7AmYJy3PGv7VLZMTeFYE1aTr331bmocfCtEY1ucSkqq8LXe7Kw/0wRthzPBwDcGuGLVVNvq1duf1YR9mQWYlHyKQDAJxNuwd11WuzMNRbs/K0A/SP9EPf5Lhw6a8Sd3QLxf/H97K7hibwS/PunXzHzri7oFGgfzqxWgZHzk/FrXin8vbS4WFplt3/bi3cg0t8T5VU16DFrs7TdFqZyiivwt/VH8fhtkegf6Sftf2bZAaw9WPu5Zc69GxarwKYjuYju0AZtvHSN+syaQ2W1Bd3e3AQASJt1F3adKsTU/6WinY87trww9LrX9VxxBYb8cytsv/rurhqkzx4hjf8jas3YPUetQkPdC8O6BmJYnbWWerYz4K6oIBSXVSPMzx3niitQVWNFjVXg+7RzcHPR4LHoCHjpXNAp0AuP3xaBLcfz4KJW43RBWb3WqXY+7jBVViMjrwQZeSVoyPRhnfDCiC7Yf6YIpy6WYXTvtgjw0mHF3myUVVmwbE8Wlu3JavC18zZd7n708XBFcXk18kxmvPJNOgAg0t8TmRfLkFVYjle/SUfpFfcEbCgwAYC5xoqp/0tFr3YG3H9zO9RYBfy9dPBxd0X6OSMSj+Yhs6AMXloX7M4sgJ+nFifySlFirn/Pwb2ni3CuuAJB3joczy1B6pkifJp0sl730X9+PoXeoQa083GHSqXCjOVp2Hg4167M1uP56PCXDVj0575S19oTS/ciu7ACpy6UYdMM+/WIfjyah1/zSuGtc8GWF+7Aa98ewob0y8ec+mUqljxxKz5PzrR7XUllNbzdXLFg22/YkJ6LfaeLsOWFofC+NEngYHaxVPZAdjHWHszB4h2nEerrjkmDIxHTPQjbM/JxR9dAhPl5NPgZNwdTZTXM1VaM/vBnAIDWRQ2DuysGd/ZHgLcO54orsCjpFJ6L6XzN4/xy4gKsArgpzAe/5Zei1FyDX/NK0SOEf+ARNQZbmpoIW5puPBdKzNh7uhBtPLVwc9XgvLESsVFBKC6vxsbDucg1VSKijQf6hfvBy80FCV/tR1ZhOdYkDEKAtw45xRXILzHjpjAfALWz+X7+9QK+3pOFnScLYLEKqFXAmJvaYczN7fDDwRysTj0LN1c13rynB8b1C8O8Tcfx+c+Z8NK54NnhnTBxUCQ+Sz5Vb2zX7Ht7YGHSSeSZzPXO4/HbIqRumStpXdTXXc6hnY87aqxWXCgxo24jnZurGpXV118KwkvngtIrwpdGrUK3YG8cybncSvfIgPaIaOMhrUUEAKlvxEgtPeYaC2L/nYzTBeV45s5OeGFEV5SZa/DN/rPw8dDi+RVp0oSAhvRqZ0D6OaP0fOwtoejZTo9b2vvivkvdntfTq50BP0wfhIKyKvi4u16zpaaqxoqCMjPaeOqgdXGsRedMQRkOnTViyc7TKK2swckLpXYto1Eheqx/dggAYO3BHDyz7AC0LmpsnnG71O2bZ6pE3Ge70C/CF/Me7AMAmLkiDd8eOIfpwzphf1YRdp4sAFD7uzH7T1EoLKuCm6saHlr+HU2tD7vnZMDQRLZ/So7ckw+o7dKyCmHX/VNUVgXdFV9e1RYrVIDdF/T2jHxsPpKLMrMFencXvH53DyT9egGLkk9Co1KhV6gBiUfz8N5DfTCgQxukninClmN5+PnERaSfM8Jb54LSqhoIURtqbm7vg7SsYqllSaUC7u7ZFrd1aoMxN7WDh1aD4vJqXCg146FPU2CsqO0m9Na54OZwX/SP8JW6FP/UJwTlVTX46Vh+vXPu1c6A8DYeeHRgOPpH+iG7sAJ//r/dyCosb/Az8ta5IMTHvXa1+YpqpGUXI9Bbh60v3gEvnf0X/OFzRtzz0S/S82fv7ISTF8qwPv28XTm1CmgoW6lVgJurBuVVtRMQAr11yC+pH0Lb+dS2WAbpdbi9cwB6hRoQFWJAj7Z6aUmMvacLMfm/+1BUXg03VzUm394Rz8d0ln43Tl4ohZ+HFj4erjh41ohIf0+knCzA01+l1mvdtOkQ4IkPx9+Mnu0MAGp/3x77Yg9+PnERAd46PB/TBeP6heL5lQelrsbdfxmOQG8dBv9zG84VV+DLSf2RcrIAn2w/KR33i8f74dllafD1dMXqqbchSO8Gi1Xg691nEOLjjuHdgxquENENgqFJBgxNpBTlVTXw0LqgqKwK54or0DXYG64aNcw1FpwpKEfnQC8UlFXB/ypjeY6dN2FN2jnc1T0It7T3lbpJj+QYsWTHabwU2xVQAatTz+K2jv64WGKGr6crLpRUYXj3wHozCU9fLMN/fjmF0sqa2lCkd8Mt7X3x+c+n6rUc6VzUWPDILYjp0fAX+diFO5F6pghA7arZW47lI+Hr/egf6YfINp5YsS8bz97ZCZkF5VKwsHnngV7o2c6AD346gZjugXj41jAUllXhix2ZWLDtZENvZ0etAkJ9PZBrrJQWdq3rzm6BGNolAEdzTFixLxu23uWGApy/lw6mimq74xycNQIGD/s1x84UlGHswp31xnbZ/PW+KPQL98PdH/4MF7UKh2aPQPKvFzH1f6kNlu/g74kP427GwqSTWH+oNmze2ycEAyL98OeB4df9DBr7hwORM2BokgFDE1HTKjPX4LyxAjnFlcg1VsJUWY2RPYMR6nv1MUW/5ZdizrqjSBjWCf0j/SCEQH6JGYHeOqhUKhSUmuHnqUWJuQZf7cpCRBsPrEo9i3t6t8UDt4Q2eMyqGiuW783CrRF+WLE3G6XmGozqGQwhgINni3H4nBHp50y4WGrfKtU1yBvfTrsNK/ZmY876o1dtQaorukMbfDmpP1w0alittXWftHQv7uwWiBdGNDzbrdRcgxV7s/HR1hMoLre/ma+fpxYeWg3OFlUgNioIix7tB2NFNUZ9kIzyaku98tfy3PDOuL1LAEwV1fj5xEW4uqgQrHdDqK8H7uwWiHWHcvB+4q/QatQY2KENIv098VC/UGncmDMoKDWjsKwKnbm2FdXB0CQDhiai1i3PVIlf80rg66FFUXkVerfzkVqGfs0rwdqDOcjILUGNVeC+m0Jwc5gv1h7KQYC3Dsv3ZKF3qA9eHdXtd68pVVxeha92Z6FjgBduCvNBzPtJ0lgyD60GiTOHop2POwBcum0R8OWuM3h77RF0DPDC108NRMJX+7HndCEA4NGB4fhq95kGW8IcpVLVzk51d9XgYmkVSs010Lu5ontbbwR6u8EqBCxWAYsQsFprf7YKgQulVTh1oXbAf69QA9QqFXw9tdC5qFFZbUGNRcBFo4JGrYIKKliFgFXUzq60itrjCQFYhUBReTUqqyzwdnPBL79dhLnGiiGd/RGkd0NFlQXt23hAo1LVtvxd+q8Kl/57aamSKosV5ku3c7IKAZ2LGjoXDXQuamhd1NC5qFFSWYPNR3ORa6zE8G5BCDa4Qe/uCm83F6SeLsKR80YMjGwDtVqF88ZK9Ak1SF3M2UXlOFdUgQh/TwR6u6G8qgZ+nlqoVEDmxXKYaywI9/OEh7b2PQHgQqkZpeYaeOtcUFxe2yoZ6uuOovJqeGg1OFdcgUPZRgzq1AaV1VbsziyAv5cO/SL8UFltgcHdFT4erig3W1BeVQOdqwYeWg3cXTWoqLZg0+Fc7PjtItq38YCbiwaZF8sQbHDDPb1D0CfUAIHaWZ3VFgFvNxccyTHi4Fkj+kf4oXOQF0wV1fD10OLXvBL8ll+K3qE+MNdY8fOJC/D11OL2zgHw1GlQZq6Bn6cOF0rMUKlqx0rqXDR2/3VRq3HeWInswnK083XHoE7+v/+XsgEMTTJgaCIiZ2KsqMbB7GIczzXhlva+6Bfh12C5/JJK6Fw0MLi7wlhRjde/S0eYnwdeju2KA9nF8NS64KdjeVh7MKf2S9rNFeF+HjDXWFBcUY2M3BKUV1ngqdXUduGpaidR7D9ThNMFDY9VI/q97r+5Hf798E1NekyGJhkwNBFRa1ReVYOc4koE6XV2XXFCCBSUVeG3/FJUW6zw99LB280FF0urcOy8CcXl1dCoAbWqtsVIo1ZJPxvcXdExwAunLpQix1gJF7UKBWVVqLZY4eGqgUajgsUiUGOtvdG3us5rVSpcajlSQa1WwUungbvWBelni6FSqfCnPiFI+vUCSs018NK54MKlwf7iUmuVwKX/itptKhWg1dS2KGld1FCrVKiqqW15qn1YYK6xQqtRo0+oAb6eWhzPLYGpohqmyhqUVFbD3VWDnu0MOFtUgTJzDYINbjhbVA5ztRUCgL+XFmG+HsgqLMfFUjO83FxRVFYFc40FnQK9odWocLaoQno/q6h9jafOBaWVNfD10MIqxKUJCrV3BVCpau++cPy8CXkmM0b1DEZpVQ32nS5CmK87Ss0WmCqq4eXmAnetBuZqC8qrah9CCNwa4Yc7uwfiZH4pfj5xEbFRwai2WLHhcC7OFpXDVa2Gm6saKpUKxopqtPfzQEQbDxw7X3LpHFyQZ6pE50BvhPi44UiOCe6uGkR3bIOSyhok/3oBWhc13Fw1yDdVItjgJt2tobK69jOtrLagstqKaosVQXo3hPq6Y0hnf0y+vWOT/g4zNMmAoYmIiEh5GvP9zeVgiYiIiBzA0ERERETkAIYmIiIiIgcwNBERERE5gKGJiIiIyAEMTUREREQOYGgiIiIicgBDExEREZEDGJqIiIiIHMDQREREROQAhiYiIiIiBzA0ERERETmAoYmIiIjIAQxNRERERA5wkbsCNwohBADAZDLJXBMiIiJylO172/Y9fi0MTU2kpKQEABAWFiZzTYiIiKixSkpKYDAYrllGJRyJVnRdVqsVOTk58Pb2hkqlatJjm0wmhIWFITs7G3q9vkmPTY3H6+F8eE2cC6+Hc+H1uDYhBEpKShASEgK1+tqjltjS1ETUajVCQ0Ob9T30ej1/4Z0Ir4fz4TVxLrwezoXX4+qu18Jkw4HgRERERA5gaCIiIiJyAEOTAuh0Orz11lvQ6XRyV4XA6+GMeE2cC6+Hc+H1aDocCE5ERETkALY0ERERETmAoYmIiIjIAQxNRERERA5gaCIiIiJyAEOTk1uwYAEiIiLg5uaGAQMGYM+ePXJX6YaUnJyMe++9FyEhIVCpVFizZo3dfiEEZs2ahbZt28Ld3R0xMTE4ceKEXZnCwkJMmDABer0ePj4+mDRpEkpLS1vwLG4cc+fOxa233gpvb28EBgZizJgxyMjIsCtTWVmJhIQEtGnTBl5eXhg7dizy8vLsymRlZWH06NHw8PBAYGAgXnrpJdTU1LTkqdwwFi5ciN69e0sLJEZHR2Pjxo3Sfl4Peb3zzjtQqVSYMWOGtI3XpOkxNDmxFStWYObMmXjrrbewf/9+9OnTB7GxscjPz5e7ajecsrIy9OnTBwsWLGhw/7x58/Dhhx/i008/xe7du+Hp6YnY2FhUVlZKZSZMmIAjR44gMTER69atQ3JyMiZPntxSp3BDSUpKQkJCAnbt2oXExERUV1djxIgRKCsrk8o8//zzWLt2LVatWoWkpCTk5OTggQcekPZbLBaMHj0aVVVV2LlzJ5YuXYolS5Zg1qxZcpyS4oWGhuKdd95Bamoq9u3bhzvvvBP33Xcfjhw5AoDXQ0579+7FokWL0Lt3b7vtvCbNQJDT6t+/v0hISJCeWywWERISIubOnStjrW58AMR3330nPbdarSI4OFi8++670rbi4mKh0+nEsmXLhBBCHD16VAAQe/fulcps3LhRqFQqce7cuRar+40qPz9fABBJSUlCiNrP39XVVaxatUoqc+zYMQFApKSkCCGE2LBhg1Cr1SI3N1cqs3DhQqHX64XZbG7ZE7hB+fr6iv/85z+8HjIqKSkRnTt3FomJiWLo0KHiueeeE0Lw30hzYUuTk6qqqkJqaipiYmKkbWq1GjExMUhJSZGxZq1PZmYmcnNz7a6FwWDAgAEDpGuRkpICHx8f9OvXTyoTExMDtVqN3bt3t3idbzRGoxEA4OfnBwBITU1FdXW13TXp1q0b2rdvb3dNevXqhaCgIKlMbGwsTCaT1DpCv4/FYsHy5ctRVlaG6OhoXg8ZJSQkYPTo0XafPcB/I82FN+x1UhcvXoTFYrH7ZQaAoKAgHD9+XKZatU65ubkA0OC1sO3Lzc1FYGCg3X4XFxf4+flJZej3sVqtmDFjBgYNGoSePXsCqP28tVotfHx87MpeeU0auma2fdR46enpiI6ORmVlJby8vPDdd9+hR48eSEtL4/WQwfLly7F//37s3bu33j7+G2keDE1E5NQSEhJw+PBh/PLLL3JXpdXr2rUr0tLSYDQasXr1asTHxyMpKUnuarVK2dnZeO6555CYmAg3Nze5q9NqsHvOSfn7+0Oj0dSb6ZCXl4fg4GCZatU62T7va12L4ODgegP0a2pqUFhYyOv1B0yfPh3r1q3Dtm3bEBoaKm0PDg5GVVUViouL7cpfeU0auma2fdR4Wq0WnTp1Qt++fTF37lz06dMH8+fP5/WQQWpqKvLz83HLLbfAxcUFLi4uSEpKwocffggXFxcEBQXxmjQDhiYnpdVq0bdvX2zZskXaZrVasWXLFkRHR8tYs9YnMjISwcHBdtfCZDJh9+7d0rWIjo5GcXExUlNTpTJbt26F1WrFgAEDWrzOSieEwPTp0/Hdd99h69atiIyMtNvft29fuLq62l2TjIwMZGVl2V2T9PR0uzCbmJgIvV6PHj16tMyJ3OCsVivMZjOvhwyGDx+O9PR0pKWlSY9+/fphwoQJ0s+8Js1A7pHodHXLly8XOp1OLFmyRBw9elRMnjxZ+Pj42M10oKZRUlIiDhw4IA4cOCAAiPfff18cOHBAnDlzRgghxDvvvCN8fHzE999/Lw4dOiTuu+8+ERkZKSoqKqRjjBw5Utx8881i9+7d4pdffhGdO3cWcXFxcp2Soj399NPCYDCI7du3i/Pnz0uP8vJyqczUqVNF+/btxdatW8W+fftEdHS0iI6OlvbX1NSInj17ihEjRoi0tDSxadMmERAQIF577TU5TknxXn31VZGUlCQyMzPFoUOHxKuvvipUKpX48ccfhRC8Hs6g7uw5IXhNmgNDk5P76KOPRPv27YVWqxX9+/cXu3btkrtKN6Rt27YJAPUe8fHxQojaZQfefPNNERQUJHQ6nRg+fLjIyMiwO0ZBQYGIi4sTXl5eQq/Xi4kTJ4qSkhIZzkb5GroWAMTixYulMhUVFWLatGnC19dXeHh4iPvvv1+cP3/e7jinT58Wo0aNEu7u7sLf31+88MILorq6uoXP5sbwxBNPiPDwcKHVakVAQIAYPny4FJiE4PVwBleGJl6TpqcSQgh52riIiIiIlINjmoiIiIgcwNBERERE5ACGJiIiIiIHMDQREREROYChiYiIiMgBDE1EREREDmBoIiIiInIAQxMRUTNRqVRYs2aN3NUgoibC0EREN6THH38cKpWq3mPkyJFyV42IFMpF7goQETWXkSNHYvHixXbbdDqdTLUhIqVjSxMR3bB0Oh2Cg4PtHr6+vgBqu84WLlyIUaNGwd3dHR06dMDq1avtXp+eno4777wT7u7uaNOmDSZPnozS0lK7Ml988QWioqKg0+nQtm1bTJ8+3W7/xYsXcf/998PDwwOdO3fGDz/80LwnTUTNhqGJiFqtN998E2PHjsXBgwcxYcIEjB8/HseOHQMAlJWVITY2Fr6+vti7dy9WrVqFn376yS4ULVy4EAkJCZg8eTLS09Pxww8/oFOnTnbv8fbbb2PcuHE4dOgQ7r77bkyYMAGFhYUtep5E1ETkvmMwEVFziI+PFxqNRnh6eto9/v73vwshhAAgpk6daveaAQMGiKeffloIIcRnn30mfH19RWlpqbR//fr1Qq1Wi9zcXCGEECEhIeL111+/ah0AiDfeeEN6XlpaKgCIjRs3Ntl5ElHL4ZgmIrphDRs2DAsXLrTb5ufnJ/0cHR1tty86OhppaWkAgGPHjqFPnz7w9PSU9g8aNAhWqxUZGRlQqVTIycnB8OHDr1mH3r17Sz97enpCr9cjPz//954SEcmIoYmIblienp71usuairu7u0PlXF1d7Z6rVCpYrdbmqBIRNTOOaSKiVmvXrl31nnfv3h0A0L17dxw8eBBlZWXS/h07dkCtVqNr167w9vZGREQEtmzZ0qJ1JiL5sKWJiG5YZrMZubm5dttcXFzg7+8PAFi1ahX69euHwYMH46uvvsKePXvwf//3fwCACRMm4K233kJ8fDxmz56NCxcu4JlnnsGjjz6KoKAgAMDs2bMxdepUBAYGYtSoUSgpKcGOHTvwzDPPtOyJElGLYGgiohvWpk2b0LZtW7ttXbt2xfHjxwHUzmxbvnw5pk2bhrZt22LZsmXo0aMHAMDDwwObN2/Gc889h1tvvRUeHh4YO3Ys3n//felY8fHxqKysxL///W+8+OKL8Pf3x4MPPthyJ0hELUolhBByV4KIqKWpVCp89913GDNmjNxVISKF4JgmIiIiIgcwNBERERE5gGOaiKhV4sgEImostjQREREROYChiYiIiMgBDE1EREREDmBoIiIiInIAQxMRERGRAxiaiIiIiBzA0ERERETkAIYmIiIiIgcwNBERERE54P8BI8x9zgDDyCMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now, train the network the usual way.\n",
    "# We change the output layer to have a single neuron and no activation function.\n",
    "# We also change the loss function to be the mean squared error (MSE).\n",
    "BATCH_SIZE = 85\n",
    "\n",
    "# Split the dataset into a training and a validation set.\n",
    "train_reg_data = data.sample(frac=TRAIN_VAL_RATIO, random_state=42)\n",
    "val_reg_data = data.drop(train_data.index)\n",
    "\n",
    "# Create the datasets.\n",
    "train_dataset_regression = DiabetesRegressionDataset(train_reg_data, transform=transform)\n",
    "val_dataset_regression = DiabetesRegressionDataset(val_reg_data, transform=transform)\n",
    "\n",
    "# Create the dataloaders.\n",
    "train_loader_regression = DataLoader(train_dataset_regression, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_regression = DataLoader(val_dataset_regression, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Create the neural network.\n",
    "classifer_regression = DiabetesRegressionModel()\n",
    "\n",
    "# Train the network.\n",
    "costs1 = train(classifer_regression, train_loader_regression, num_epochs=300, lr=0.001, wd=0.001,\n",
    "               loss_func='MSE', try_cuda=True, print_cost=True, print_stride=20)\n",
    "print(\"\\nREDUCED LEARNING RATE TO 0.0001\\n\")\n",
    "costs2 = train(classifer_regression, train_loader_regression, num_epochs=150, lr=0.0001, wd=0.001,\n",
    "               loss_func='MSE', try_cuda=True, print_cost=True, print_stride=20)\n",
    "\n",
    "# Evaluate the network.\n",
    "regression_costs = np.array(costs1 + costs2)\n",
    "\n",
    "plt.plot(regression_costs)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 2569.23\n",
      "Validation MSE: 3297.98\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the network.\n",
    "X_train : np.ndarray = train_reg_data.drop('Y', axis=1).values\n",
    "y_train : np.ndarray = train_reg_data['Y'].values  # type: ignore\n",
    "X_val : np.ndarray = val_reg_data.drop('Y', axis=1).values\n",
    "y_val : np.ndarray = val_reg_data['Y'].values  # type: ignore\n",
    "\n",
    "with torch.no_grad():\n",
    "    classifer_regression.cpu().eval()\n",
    "    y_hat_train = classifer_regression(torch.from_numpy(X_train).float()).squeeze()\n",
    "    y_hat_val = classifer_regression(torch.from_numpy(X_val).float()).squeeze()\n",
    "\n",
    "train_mse = F.mse_loss(y_hat_train, torch.from_numpy(y_train)).item()\n",
    "val_mse = F.mse_loss(y_hat_val, torch.from_numpy(y_val)).item()\n",
    "\n",
    "print(f\"Train MSE: {train_mse:.2f}\")\n",
    "print(f\"Validation MSE: {val_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Mean Squared Error: 2921.68\n",
      "[VAL] Mean Squared Error: 3499.15\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "True",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Predicted",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "904c7b75-3cac-4310-a4dc-6ba2ac7d337d",
       "rows": [
        [
         "0",
         "219",
         "152.1055117370579"
        ],
        [
         "1",
         "70",
         "184.81295951662457"
        ],
        [
         "2",
         "202",
         "146.86861006773887"
        ],
        [
         "3",
         "230",
         "289.45795232018463"
        ],
        [
         "4",
         "111",
         "121.51693290394564"
        ],
        [
         "5",
         "84",
         "97.0974430770124"
        ],
        [
         "6",
         "242",
         "242.91734252062042"
        ],
        [
         "7",
         "272",
         "196.6590510045187"
        ],
        [
         "8",
         "94",
         "92.47403734558635"
        ],
        [
         "9",
         "96",
         "115.8844158596567"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219</td>\n",
       "      <td>152.105512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>184.812960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202</td>\n",
       "      <td>146.868610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230</td>\n",
       "      <td>289.457952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111</td>\n",
       "      <td>121.516933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84</td>\n",
       "      <td>97.097443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>242</td>\n",
       "      <td>242.917343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>272</td>\n",
       "      <td>196.659051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94</td>\n",
       "      <td>92.474037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>96</td>\n",
       "      <td>115.884416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   True   Predicted\n",
       "0   219  152.105512\n",
       "1    70  184.812960\n",
       "2   202  146.868610\n",
       "3   230  289.457952\n",
       "4   111  121.516933\n",
       "5    84   97.097443\n",
       "6   242  242.917343\n",
       "7   272  196.659051\n",
       "8    94   92.474037\n",
       "9    96  115.884416"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparison with normal linear regression.\n",
    "X : np.ndarray = train_reg_data.drop('Y', axis=1).values\n",
    "y : np.ndarray = train_reg_data['Y'].values  # type: ignore\n",
    "\n",
    "w = np.linalg.pinv(X.T @ X) @ X.T @ y\n",
    "\n",
    "y_hat = X @ w\n",
    "\n",
    "train_mse = np.mean((y - y_hat) ** 2)\n",
    "val_mse = np.mean((y_val - X_val @ w) ** 2)  # type: ignore\n",
    "\n",
    "print(f\"[TRAIN] Mean Squared Error: {train_mse:.2f}\")\n",
    "print(f\"[VAL] Mean Squared Error: {val_mse:.2f}\")\n",
    "\n",
    "pd.DataFrame({'True': y, 'Predicted': y_hat}).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
