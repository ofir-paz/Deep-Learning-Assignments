{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher's Assignment - Extra Credit #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Author:*** *Ofir Paz* $\\qquad$ ***Version:*** *22.07.2024* $\\qquad$ ***Course:*** *22961 - Deep Learning* \\\n",
    "***Extra Assignment Course:*** *20999 - Extra Assignment 4*\n",
    "\n",
    "Welcome to the second question of the extra assignment #2 as part of the course *Deep Learning*. \\\n",
    "In this question we will train an auto encoder to denoise a language dataset and afterwards use transfer learning on the trained model for a classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # pytorch.\n",
    "import torch.nn as nn  # neural network module.\n",
    "import torch.nn.functional as F  # neural network functional module.\n",
    "from torch.utils.data import DataLoader, Dataset  # data handling.\n",
    "import torchtext; torchtext.disable_torchtext_deprecation_warning()\n",
    "from torchtext.vocab import build_vocab_from_iterator  # vocabulary builder.\n",
    "import matplotlib.pyplot as plt  # plotting module.\n",
    "import datasets as ds  # public dataset module.\n",
    "from base_model import BaseModel  # base model class.\n",
    "\n",
    "# Type hinting.\n",
    "from torch import Tensor\n",
    "from torchtext.vocab import Vocab\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add noise to a language dataset, I thought of Four options:\n",
    "1. Make duplicates of random words that appear in the sentence. For example: \n",
    "$$\\text{\"The princess is beautiful\"} \\rightarrow \\text{\"The princess is is beautiful\"}$$\n",
    "2. Add a random word somewhere in the sentence. For example:\n",
    "$$\\text{\"The princess is beautiful\"} \\rightarrow \\text{\"The house princess is beautiful\"}$$\n",
    "3. Changing the order of words in the sentence. For example:\n",
    "$$\\text{\"The princess is beautiful\"} \\rightarrow \\text{\"The beautiful is princess\"}$$\n",
    "4. Changing a random token in the sentence to the unknown token. For example:\n",
    "$$\\text{\"The princess is beautiful\"} \\rightarrow \\text{\"The <unk> is beautiful\"}$$\n",
    "\n",
    "The simplest option and the one that seems like it would work best in language processing is option 4, so I will implement that only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(sentence_tokens: list[int], vocab: Vocab, noise_term: float = 0.1) -> list[int]:\n",
    "    \"\"\"\n",
    "    Add noise to the sentence tokens.\n",
    "\n",
    "    Args:\n",
    "        sentence_tokens (list[int]): Sentence tokens.\n",
    "        vocab (Vocab): Vocabulary.\n",
    "        noise_term (float): Noise term.\n",
    "\n",
    "    Returns:\n",
    "        list[int]: Noisy sentence tokens.\n",
    "    \"\"\"\n",
    "    return [token if torch.rand(1) > noise_term else vocab[\"<unk>\"] for token in sentence_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading & Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AutoDenoiser(nn.Module):\n",
    "#     def __init__(self) -> None:\n",
    "#         super().__init__()\n",
    "#         self.encoder = nn.TransformerEncoderLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SST-2 dataset.\n",
    "dataset: ds.DatasetDict = ds.load_dataset(\"glue\", \"sst2\")  # type: ignore\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "validation_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SST-2 dataset.\n",
    "class SST2Dataset(Dataset):\n",
    "    def __init__(self, dataset: ds.Dataset, vocab: Vocab) -> None:\n",
    "        self.sentences = list(map(lambda seq: torch.tensor(vocab(seq.split())), dataset[\"sentence\"]))\n",
    "        self.labels = torch.tensor(dataset[\"label\"], dtype=torch.long)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[Tensor, Tensor]:\n",
    "        return self.sentences[idx], self.labels[idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
