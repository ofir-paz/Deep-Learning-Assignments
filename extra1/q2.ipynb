{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher's Assignment - Extra Credit #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Author:*** *Ofir Paz* $\\qquad$ ***Version:*** *15.07.2024* $\\qquad$ ***Course:*** *22961 - Deep Learning* \\\n",
    "***Extra Assignment Course:*** *20998 - Extra Assignment 3*\n",
    "\n",
    "Welcome to the second question of the extra assignment #1 as part of the course *Deep Learning*. \\\n",
    "In this question we will implement an RNN block with a basic pass-through control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # pytorch.\n",
    "import torch.nn as nn  # neural network module.\n",
    "import torch.nn.functional as F  # neural network functional module.\n",
    "from torch.utils.data import DataLoader, Dataset  # data handling.\n",
    "import torchtext; torchtext.disable_torchtext_deprecation_warning()\n",
    "from torchtext.vocab import build_vocab_from_iterator  # vocabulary builder.\n",
    "import matplotlib.pyplot as plt  # plotting module.\n",
    "import datasets as ds  # public dataset module.\n",
    "from base_model import BaseModel  # base model class.\n",
    "\n",
    "# Type hinting.\n",
    "from torch import Tensor\n",
    "from torchtext.vocab import Vocab\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRNNCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom RNN cell class.\n",
    "\n",
    "    Use another hidden state - the pass-through hidden state - to control the hidden state of the RNN cell.\n",
    "    \n",
    "    :math:`h^{\\hat}_t = tanh(W_{ih}x_t + b_{ih} + W_{hh}h_{t-1} + b_{hh})`\n",
    "    :math:`r_t = softmax(W_{ih}x_t + b_{ih})`\n",
    "    :math:`h_t = h^{\\hat}_t \\odot r_t`  # element-wise multiplication.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim: int, hidden_dim: int) -> None:\n",
    "        super(CustomRNNCell, self).__init__()\n",
    "        self.hidden_state = torch.zeros(hidden_dim)\n",
    "        self.input_linear = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.hidden_linear = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.regular_activation = nn.Tanh()\n",
    "\n",
    "        self.pass_through_layer = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.pass_through_activation = nn.Softmax()\n",
    "\n",
    "    def forward(self, one_embedded_token: Tensor) -> None:\n",
    "        Z1 = self.input_linear(one_embedded_token)\n",
    "        Z2 = self.hidden_linear(self.hidden_state)\n",
    "        h_hat_t = self.regular_activation(Z1 + Z2)\n",
    "\n",
    "        r_t = self.pass_through_activation(self.pass_through_layer(one_embedded_token))\n",
    "        self.hidden_state = h_hat_t * r_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing The Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset to try to fit on.\n",
    "full_dataset: ds.DatasetDict = ds.load_dataset(\"glue\", \"sst2\")  # type: ignore\n",
    "big_train_dataset = full_dataset[\"train\"]\n",
    "big_validation_dataset = full_dataset[\"validation\"]\n",
    "train_dataset = big_train_dataset.select(range(1000))  # small dataset for testing.\n",
    "validation_dataset = big_validation_dataset.select(range(500))  # small dataset for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vocabulary.\n",
    "train_sentence_list = train_dataset[\"sentence\"]\n",
    "vocab = build_vocab_from_iterator(map(str.split, train_sentence_list), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset class.\n",
    "class SST2Dataset(Dataset):\n",
    "    def __init__(self, dataset: ds.Dataset, vocab: Vocab) -> None:\n",
    "        self.sentences = list(map(lambda seq: torch.tensor(vocab(seq.split())), dataset[\"sentence\"]))\n",
    "        self.labels = torch.tensor(dataset[\"label\"], dtype=torch.long)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[Tensor, Tensor]:\n",
    "        return self.sentences[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloaders.\n",
    "train_set = SST2Dataset(train_dataset, vocab)\n",
    "validation_set = SST2Dataset(validation_dataset, vocab)\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(BaseModel):\n",
    "    \"\"\"\n",
    "    RNN model class.\n",
    "\n",
    "    The RNN model class uses the custom RNN cell to create a custom RNN model.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size: int, embed_dim: int, hidden_dim: int, num_classes: int) -> None:\n",
    "        super(RNN, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn_cell = CustomRNNCell(embed_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, sentence_tokens: Tensor) -> Tensor:\n",
    "        sentence_tokens = sentence_tokens.squeeze(0)\n",
    "        embedded = self.embed(sentence_tokens)\n",
    "        for token in embedded:\n",
    "            self.rnn_cell(token)\n",
    "        return self.fc(self.rnn_cell.hidden_state).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model.\n",
    "model = RNN(len(vocab), 20, 100, 2)\n",
    "\n",
    "model.fit(train_loader, validation_loader, num_epochs=20, lr=0.001, try_cuda=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
