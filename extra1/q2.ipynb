{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teacher's Assignment - Extra Credit #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Author:*** *Ofir Paz* $\\qquad$ ***Version:*** *15.07.2024* $\\qquad$ ***Course:*** *22961 - Deep Learning* \\\n",
    "***Extra Assignment Course:*** *20998 - Extra Assignment 3*\n",
    "\n",
    "Welcome to the second question of the extra assignment #1 as part of the course *Deep Learning*. \\\n",
    "In this question we will implement an RNN block with a basic pass-through control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # pytorch.\n",
    "import torch.nn as nn  # neural network module.\n",
    "import torch.nn.functional as F  # neural network functional module.\n",
    "from torch.utils.data import DataLoader, Dataset  # data handling.\n",
    "import torchtext; torchtext.disable_torchtext_deprecation_warning()\n",
    "from torchtext.vocab import build_vocab_from_iterator  # vocabulary builder.\n",
    "import matplotlib.pyplot as plt  # plotting module.\n",
    "import datasets as ds  # public dataset module.\n",
    "from base_model import BaseModel  # base model class.\n",
    "\n",
    "# Type hinting.\n",
    "from torch import Tensor\n",
    "from torchtext.vocab import Vocab\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomRNNCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom RNN cell class.\n",
    "\n",
    "    Use another hidden state - the pass-through hidden state - to control the hidden state of the RNN cell.\n",
    "    \n",
    "    :math:`h^{\\hat}_t = tanh(W_{ih}x_t + b_{ih} + W_{hh}h_{t-1} + b_{hh})`\n",
    "    :math:`r_t = softmax(W_{ih}x_t + b_{ih})`\n",
    "    :math:`h_t = h^{\\hat}_t \\odot r_t`  # element-wise multiplication.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim: int, hidden_dim: int) -> None:\n",
    "        super(CustomRNNCell, self).__init__()\n",
    "        self.input_linear = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.hidden_linear = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.regular_activation = nn.Tanh()\n",
    "\n",
    "        self.pass_through_layer = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.pass_through_activation = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, one_embedded_token: Tensor, hidden_state: Tensor) -> Tensor:\n",
    "        Z1 = self.input_linear(one_embedded_token)\n",
    "        Z2 = self.hidden_linear(hidden_state)\n",
    "        h_hat_t = self.regular_activation(Z1 + Z2)\n",
    "        \n",
    "        r_t = self.pass_through_activation(self.pass_through_layer(one_embedded_token))\n",
    "        new_hidden_state = h_hat_t * r_t\n",
    "\n",
    "        return new_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing The Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset to try to fit on.\n",
    "full_dataset: ds.DatasetDict = ds.load_dataset(\"glue\", \"sst2\")  # type: ignore\n",
    "big_train_dataset = full_dataset[\"train\"]\n",
    "big_validation_dataset = full_dataset[\"validation\"]\n",
    "train_dataset = big_train_dataset.select(range(500))  # small dataset for testing.\n",
    "validation_dataset = big_validation_dataset.select(range(250))  # small dataset for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vocabulary.\n",
    "train_sentence_list = train_dataset[\"sentence\"]\n",
    "vocab = build_vocab_from_iterator(map(str.split, train_sentence_list), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset class.\n",
    "class SST2Dataset(Dataset):\n",
    "    def __init__(self, dataset: ds.Dataset, vocab: Vocab) -> None:\n",
    "        self.sentences = list(map(lambda seq: torch.tensor(vocab(seq.split())), dataset[\"sentence\"]))\n",
    "        self.labels = torch.tensor(dataset[\"label\"], dtype=torch.long)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[Tensor, Tensor]:\n",
    "        return self.sentences[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloaders.\n",
    "train_set = SST2Dataset(train_dataset, vocab)\n",
    "validation_set = SST2Dataset(validation_dataset, vocab)\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n",
    "validation_loader = DataLoader(validation_set, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(BaseModel):\n",
    "    \"\"\"\n",
    "    RNN model class.\n",
    "\n",
    "    The RNN model class uses the custom RNN cell to create a custom RNN model.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size: int, embed_dim: int, hidden_dim: int, num_classes: int) -> None:\n",
    "        super(RNN, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn_cell = CustomRNNCell(embed_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, sentence_tokens: Tensor) -> Tensor:\n",
    "        batch_size = sentence_tokens.size(0)\n",
    "        hidden_state = torch.zeros(batch_size, self.rnn_cell.hidden_linear.out_features, \n",
    "                                   device=sentence_tokens.device)\n",
    "        embedded = self.embed(sentence_tokens)\n",
    "        \n",
    "        for i in range(embedded.size(1)):\n",
    "            hidden_state = self.rnn_cell(embedded[:, i, :], hidden_state)\n",
    "        \n",
    "        return self.fc(hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU for training.\n",
      "[epoch: 01/15] [Train loss: 0.693663  Train Accuracy: 0.478]  [Val loss: 0.692511]  Val Accuracy: 0.516]\n",
      "[epoch: 04/15] [Train loss: 0.656935  Train Accuracy: 0.676]  [Val loss: 0.698796]  Val Accuracy: 0.512]\n",
      "[epoch: 07/15] [Train loss: 0.506899  Train Accuracy: 0.812]  [Val loss: 0.708899]  Val Accuracy: 0.520]\n",
      "[epoch: 10/15] [Train loss: 0.342418  Train Accuracy: 0.898]  [Val loss: 0.751542]  Val Accuracy: 0.476]\n",
      "[epoch: 13/15] [Train loss: 0.198692  Train Accuracy: 0.952]  [Val loss: 0.872927]  Val Accuracy: 0.524]\n",
      "[epoch: 15/15] [Train loss: 0.137132  Train Accuracy: 0.964]  [Val loss: 0.989995]  Val Accuracy: 0.512]\n",
      "Using CPU for training.\n",
      "[epoch: 16/25] [Train loss: 0.109748  Train Accuracy: 0.978]  [Val loss: 0.995595]  Val Accuracy: 0.512]\n",
      "[epoch: 18/25] [Train loss: 0.103879  Train Accuracy: 0.980]  [Val loss: 1.014728]  Val Accuracy: 0.508]\n",
      "[epoch: 20/25] [Train loss: 0.098271  Train Accuracy: 0.984]  [Val loss: 1.033314]  Val Accuracy: 0.508]\n",
      "[epoch: 22/25] [Train loss: 0.093185  Train Accuracy: 0.984]  [Val loss: 1.049319]  Val Accuracy: 0.508]\n",
      "[epoch: 24/25] [Train loss: 0.088321  Train Accuracy: 0.986]  [Val loss: 1.068013]  Val Accuracy: 0.508]\n",
      "[epoch: 25/25] [Train loss: 0.086058  Train Accuracy: 0.986]  [Val loss: 1.081436]  Val Accuracy: 0.508]\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "model = RNN(len(vocab), embed_dim=20, hidden_dim=100, num_classes=2)\n",
    "\n",
    "model.fit(train_loader, validation_loader, num_epochs=15, lr=0.001, try_cuda=False, print_stride=3)\n",
    "model.fit(train_loader, validation_loader, num_epochs=10, lr=0.0001, try_cuda=False, print_stride=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
